{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nội dung chính: \n",
    "1. N-grams\n",
    "2. Stop word\n",
    "3. Case folding\n",
    "4. Stemming\n",
    "5. Lemmatization\n",
    "6. Bài tập"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở bài viết trước, tôi đã nói về mô hình bag of word, đó là mô hình không có trật tự, chỉ số lần xuất hiện của từ được coi trọng. Chẳng hạn, ta có ví dụ \"Thắng thích xem phim. Dũng cũng thích xem phim\" thì mô hình BoW đại diện cho câu này sẽ không tiết lộ rằng động từ \"thích\" luôn theo sau tên của một người trong văn bản này. Thay vào đó thì n-grams có thể lưu trữ thông tin thứ tự này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một n-gram là một chuỗi bao gồm n phần tử được trích xuất từ một chuỗi các phần tử, luôn luôn là string. Khái niệm phần tử của một n-gram có thể là các ký tự, âm tiết, từ, vân vân. Thường thì chúng ta chỉ quan tâm n-grams của từ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với ví dụ minh hoạ bên trên ta tách n-grams được như sau (tách từ): (Dưới đây là thực hiện 2-grams, tương tự ta có 3-grams, vân vân ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thắng', 'thích'),\n",
       " ('thích', 'xem'),\n",
       " ('xem', 'phim.'),\n",
       " ('phim.', 'Dũng'),\n",
       " ('Dũng', 'cũng'),\n",
       " ('cũng', 'thích'),\n",
       " ('thích', 'xem'),\n",
       " ('xem', 'phim')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "sentence = \"Thắng thích xem phim. Dũng cũng thích xem phim\"\n",
    "token = sentence.split()\n",
    "list(ngrams(token, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi tách thế này, ta có thể dễ dàng nhận thấy những từ nào hay đi cặp với nhau. Nó sử dụng cho các bước xử lý sau này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Stop Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StopWords là những từ xuất hiện nhiều trong ngôn ngữ tự nhiên, tuy nhiên lại không mang nhiều ý nghĩa. Ở tiếng việt StopWords là những từ như: để, này, kia... Tiếng anh là những từ như: is, that, this... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví vậy, trong <b>đa số</b> các bài toàn NLP thì loại bỏ stop word đem lại hiệu quả. (Đôi khi nó cũng có ý nghĩa đấy, nên chỉ dùng từ đa số được thôi). Để loại bỏ Stop word thường có 2 hướng chính:\n",
    "1. Dùng từ điền\n",
    "2. Loại bỏ theo tuần suất xuất hiện của từ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Dùng từ điển"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cách này khá đơn giản, ta có tập từ điển và tiến hành lọc trong văn bản để loại bỏ các từ stop word. Ví dụ ta coi các từ \"anh, cứ, cũng, ...\" là stop word thì với câu dù anh cứ đi, em cũng kệ sau khi loại bỏ stop word ta được như hình sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/anh10.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta có thể tham khảo thêm danh sách stop word trong tiếng Việt tại đây: https://github.com/stopwords/vietnamese-stopwords/blob/master/vietnamese-stopwords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anh đi, em kệ'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code ví dụ cho minh hoạ bên trên\n",
    "sentence = \"dù anh cứ đi, em cũng kệ\"\n",
    "stop_word = [\"dù\",\"cứ\",\"cũng\"]\n",
    "token = sentence.split()\n",
    "output = [word for word in token if word not in stop_word]\n",
    "' '.join(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Còn với tiếng Anh thì trong nltk có hỗ trợ sẵn stop word. Ta có thể làm như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Thang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có thể thấy, stop word của thư viện tiếng anh hỗ trợ 179 từ. Chúng ta cùng xem 10 từ đầu tiên như thế nào:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhận thấy, stop word tiếng anh có cả những từ mà độ dài chỉ 1 ký tự như từ \"i\" ở trên. Thử kiểm tra xem trong bộ stop word này có bao nhiêu từ chỉ dài 1 ký tự:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'a', 's', 't', 'd', 'm', 'o', 'y']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sw for sw in stop_words if len(sw) == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngoài NLTK thì trong tiếng anh, thư viện sklearn cũng hỗ trợ 1 bộ stop word nhiều hơn với 318 từ. Ta gọi lệnh như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words\n",
    "len(sklearn_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Dựa theo tuần suất xuất hiện của từ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với cách này, chúng ta tiến hành đếm số lần xuất hiện của từng từ trong data sau đó sẽ loại bỏ những từ xuất hiện nhiều lần (cũng có thể là ít lần). Khoa học đã chứng minh những từ xuất hiện nhiều nhất thường là những từ không mang nhiều ý nghĩa. :v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như ví dụ dưới đây:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/anh11.png\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trên là top 50 từ xuất hiện nhiều nhất trong mỗi cuốn sách, dễ dàng nhận thấy chúng không mang nhiều ý nghĩa. Chính vì thế chúng ta sẽ loại bỏ những từ như thế này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Case folding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đơn giản đây là chuẩn hoá văn bản về chữ thường."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['house', 'visitor', 'center']\n"
     ]
    }
   ],
   "source": [
    "tokens = ['House', 'Visitor', 'Center']\n",
    "normalized_tokens = [x.lower() for x in tokens]\n",
    "print(normalized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong quá trình xử lý ngôn ngữ tự nhiên, chúng ta sẽ có nhu cầu so sánh các từ (token) với nhau. Việc so sánh này tưởng chừng như đơn giản là lấy 2 chuỗi ký tự và dùng phép “==” để kiểm tra, nhưng thực tế thì không phải là như vậy. Đối với một số ngôn ngữ, tiêu biểu là tiếng Anh, mỗi từ có thể có nhiều biến thể khác nhau. Điều này làm cho việc so sánh giữa các từ là không thể mặc dù về mặc ý nghĩa cơ bản là như nhau. Ví dụ các từ <b>“walks“, “walking“, “walked”</b> đều là các biến thể của từ <b>“walk”</b> và đều mang ý nghĩa là “đi bộ”. Vậy làm sao để so sánh các từ như thế với nhau? <b>Lemmatization</b> và <b>Stemming</b> chính là 2 kỹ thuật thường được dùng cho việc này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Stemming</b> là kỹ thuật dùng để biến đổi 1 từ về dạng gốc (được gọi là <b>stem</b> hoặc <b>root form</b>) bằng cách cực kỳ đơn giản là loại bỏ 1 số ký tự nằm ở cuối từ mà nó nghĩ rằng là biến thể của từ. Ví dụ như chúng ta thấy các từ như <b>walked, walking, walks</b> chỉ khác nhau là ở những ký tự cuối cùng, bằng cách bỏ đi các hậu tố <b>–ed, –ing</b> hoặc <b>–s</b>, chúng ta sẽ được từ nguyên gốc là <b>walk</b>. Người ta gọi các bộ xử lý <b>stemming</b> là <b>Stemmer</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhờ ý tưởng đó, ta thử code 1 hàm loại bỏ chữ 's' ở cuối các từ như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def stem(phrase):\n",
    "    return ' '.join([re.findall('^(.*ss|.*?)(s)?$',word)[0][0].strip(\"'\") for word in phrase.lower().split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(\"Walks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tương tự, ta hãy tự thiết lập các hàm khác có chức năng khác."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bởi vì nguyên tắc hoạt động của stemmer rất là đơn giản như vậy cho nên tốc độ xử lý của nó rất là nhanh, và kết quả stem đôi khi không được như chúng ta mong muốn. Chẳng hạn như từ <b>goes</b> sẽ được stem thành từ <b>goe</b> (bỏ chữ s cuối từ) trong khi đó stem của từ go vẫn là go, kết quả là 2 từ “goes” và “go” sau khi được stem thì vẫn không giống nhau. Một nhược điểm khác là nếu các từ dạng bất quy tắt như went hay spoke thì stemmer sẽ không thể đưa các từ này về dạng gốc là go hay speak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuy có các nhược điểm như trên nhưng trong thực tế Stemming vẫn được sử dụng khá phổ biến trong NLP vì nó có tốc độ xử lý nhanh và kết quả cuối cùng nhìn chung không hề tệ khi so với Lemmatization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem thêm code Stem khá đầy đủ tại: https://github.com/jedijulia/porter-stemmer/blob/master/stemmer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Lemmatization</b> sẽ xử lý thông minh hơn bằng một bộ từ điển hoặc một bộ ontology nào đó. Điều này sẽ đảm bảo rằng các từ như “goes“, “went” và “go” sẽ chắc chắn có kết quả trả về là như nhau. Kể các từ danh từ như mouse, mice cũng đều được đưa về cùng một dạng như nhau. Người ta gọi bộ xử lý lemmatization là <b>lemmatizer</b>.<br/>\n",
    "Nhược điểm của lemmatization là tốc độ xử lý khá chậm vì phải thực hiện tra cứu từ trong cơ sở dữ liệu. Trong các ứng dụng xử lý NLP mà cần độ chính xác cao hơn và thời gian không quan trọng, người ta có thể sử dụng Lemmatization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một tin vui là đối với tiếng Việt thì chúng ta không cần phải dùng 2 kỹ thuật này vì mỗi từ tiếng Việt nó không có các biến thể khác nhau (dựa trên hiểu biết của bản thân mình). Vì thế nếu bạn đang làm một ứng dụng NLP cho tiếng Việt thì cũng đừng lo về việc này, chỉ khi nào xử lý ngôn ngữ như tiếng Anh thì chắc chắn chúng ta sẽ phải quan tâm đến chúng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong tiếng anh, nltk có hỗ trợ bộ wordnet chứa các từ đông nghĩa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Thang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"better\", pos=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Bài tập"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Viết hàm sinh ra tất cả các n-gram từ một dãy cho trước (xâu ký tự hoặc danh sách). Sử dụng hàm đã viết, sinh ra word bi-gram và character bi-gram từ câu sau: \"Thắng đẹp trai\"\n",
    "2. Tự viết hàm xử lý stemming trong tiếng Anh, tìm hiểu về module steming trong python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
