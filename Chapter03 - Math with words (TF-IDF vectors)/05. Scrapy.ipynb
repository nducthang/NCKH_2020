{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nội dung chính:\n",
    "1. Giới thiệu\n",
    "2. Cài đặt Scrapy\n",
    "3. Kiến thức nền tảng\n",
    "4. Thử nghiệm với command line\n",
    "5. Thực hành"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Giới thiệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu là một phần quan trọng không thể thiếu trong Machine learning và nhiều lĩnh vực khác, để thu thập được dữ liệu thì ta có rất nhiều cách khác nhau. với sự phát triển của internet thì tận dụng và thu thập dữ liệu ngay trên các trang web là một thứ giá trị nếu như chúng ta biết khai thác hiệu quả. Và trong bài viết này, tôi giới thiệu cho các bạn một công cụ đơn giản để thu thập dữ liệu trên ngôn ngữ Python đó là Scrapy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapy là một framework được viết bằng Python, nó cấp sẵn 1 cấu trúc tương đối hoàn chỉnh để thực hiện việc crawl và extract data từ website một cách nhanh chóng và dễ dàng. Ví dụ như lấy toàn bộ hình ảnh trên 1 website; các bài viết trên các trang báo; thông tin dữ liệu các sản phẩm moblie, ô tô; các thông tin public trên facebook;..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Người dùng chỉ cần bổ sung thêm định nghĩa về dữ liệu cần lấy là xong, ví dụ như URL bắt đầu là gì, link chuyển qua trang mới, các thông tin cần lấy ở mỗi trang là gì..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cài đặt Scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trước hết máy tính của các bạn cần cài đặt python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để cài đặt scrapy, chúng ta cài đặt chúng thông qua pip với câu lệnh:\n",
    "`pip install Scrapy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Kiến thức nền tảng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để làm tốt phần này, chúng ta cần có chút kiến thức về HTML và CSS. Khi quét các trang web, tác vụ phổ biến nhất cần thực hiện là trích xuất dữ liệu từ nguồn HTML. Scrapy có cơ chế riêng để trích xuất dữ liệu. Chúng chọn một số thành phần nhất định của tài liệu HTML được chỉ định bởi các biểu thức XPath hoặc CSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truy vấn các phản hồi bằng XPath và CSS ta sử dụng: `response.xpath()` và `response.css()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mã nguồn của web được crawl về và được lưu trong một đối tượng gọi là `Selector`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ, chúng ta có một trang web đơn giản được crawl về và lưu và đối tượng Selector như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy import Selector\n",
    "sel = Selector(text=\"\"\"\n",
    "<html>\n",
    " <head>\n",
    "  <base href='http://example.com/' />\n",
    "  <title>Example website</title>\n",
    " </head>\n",
    " <body>\n",
    "  <div id='images'>\n",
    "   <a href='image1.html'>Name: My image 1 <br /><img src='image1_thumb.jpg' /></a>\n",
    "   <a href='image2.html'>Name: My image 2 <br /><img src='image2_thumb.jpg' /></a>\n",
    "   <a href='image3.html'>Name: My image 3 <br /><img src='image3_thumb.jpg' /></a>\n",
    "   <a href='image4.html'>Name: My image 4 <br /><img src='image4_thumb.jpg' /></a>\n",
    "   <a href='image5.html'>Name: My image 5 <br /><img src='image5_thumb.jpg' /></a>\n",
    "  </div>\n",
    " </body>\n",
    "</html>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Chú ý:</b> Khi thực hiện crawl trên web thì phần text của response chính là mã nguồn đc scrapy tải xuống hay nói cách khác response = sel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Một số phương thức"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi trích xuất dữ liệu ta sử dụng một số phương thức để trả về dữ liệu theo ý muốn. Có thể là trả về một mảng dữ liệu hay là phần tử đầu tiên của mảng dữ liệu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/method_extract.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Css Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như đã nói ở trên, chúng ta có truy vấn các element của web bằng xpath hoặc css, và đầu tiên, tôi sẽ giới thiệu cách truy vấn trên css. Để đơn giản, giả sử trang web của chúng ta có mã nguồn như đối tượng Selector bên trên chúng ta đã lưu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>title::text:</b> Trích chọn text trong thẻ title<br/>\n",
    "<b>*::text</b> chọn tất cả text ở trong các thẻ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Example website'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.css('title::text').extract_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n   ',\n",
       " 'Name: My image 1 ',\n",
       " '\\n   ',\n",
       " 'Name: My image 2 ',\n",
       " '\\n   ',\n",
       " 'Name: My image 3 ',\n",
       " '\\n   ',\n",
       " 'Name: My image 4 ',\n",
       " '\\n   ',\n",
       " 'Name: My image 5 ',\n",
       " '\\n  ']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.css('#images *::text').getall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dấu # ở trên có nghĩa là truy vấn các thẻ có id là images, với class thì là dấu . (Kiến thức này của CSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>foo::text</b> trả về kết quả không nếu phần tử <b>foo</b> tồn tại nhưng không chứa text.\n",
    "Sử dụng <b>default=''</b> nếu bạn muốn trả về string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.css('img::text').getall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.css('img::text').get(default='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>a::attr(href)</b> chọn giá trị thuộc tính <i>href</i> của thẻ <i>a</i>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.css('a::attr(href)').getall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trích xuất thông tin trong thẻ div có id = images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<div id=\"images\">\\n   <a href=\"image1.html\">Name: My image 1 <br><img src=\"image1_thumb.jpg\"></a>\\n   <a href=\"image2.html\">Name: My image 2 <br><img src=\"image2_thumb.jpg\"></a>\\n   <a href=\"image3.html\">Name: My image 3 <br><img src=\"image3_thumb.jpg\"></a>\\n   <a href=\"image4.html\">Name: My image 4 <br><img src=\"image4_thumb.jpg\"></a>\\n   <a href=\"image5.html\">Name: My image 5 <br><img src=\"image5_thumb.jpg\"></a>\\n  </div>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.css('div#images').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Xpath Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tương tự như Css, chúng ta có thể trích xuất thông tin trang web dựa trên Xpath."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có thể lấy XPath dễ dàng bằng tool hay sử dụng Chrome để tìm XPath."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ chúng ta sẽ lấy XPath trên stack overflow. Click chuột phải vào câu hỏi đầu tiên và chọn kiểm tra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/xp_0.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ, chúng ta lấy XPath của phần tử đầu tiên `<div class=\"summary\">`, kết quả sẽ tương tự `//*[@id=\"question-summary-59818222\"]/div[2]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/xp_1.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta có thể test lại trong Javascript console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/xp_2.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tương tự như trên, chúng ta có thể lấy xpath của bất kỳ phần tử nào của trang web bất kỳ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem thêm: https://doc.scrapy.org/en/latest/topics/selectors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Thử nghiệm với command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapy sử dụng đối tượng Request và Response để thu thập dữ liệu websites.\n",
    "Thông thường các đối tượng Request được tạo trong spider và truyền qua hệ thống cho đến khi đến trình download, thực thi yêu cầu và trả về đối tượng Response di chuyển trở lại spider đã gửi Request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapy được điều khiển thông qua command-line tool. Scrapy cung cấp một số lệnh, với nhiều mục đích thì sẽ sử dụng các nhóm lệnh khác nhau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta có thể sử dụng `scrapy shell` để kiểm tra các xpath và css của chúng ta trước khi thực hiện code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên mở cmd chạy command `scrapy shell [url]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ: `scrapy shell https://fptshop.com.vn/dien-thoai?sort=ban-chay-nhat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau đó có thể trực tiếp sử dụng các Selector để trích xuất trực tiếp, thực hiện điều này giúp kiểm tra một cách trực quan hơn. Ví dụ ta muốn tách title của bài báo, nhập `response.css('title::text').get()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/cmd.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tương tự, ta có thể test được các xpath và css của chúng ta xem đúng ý hay chưa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Thực hành"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, bạn đã có những kiến thức cơ sở nhất để thực hiện crawl một trang web, bây giờ chúng ta sẽ cùng thực hành crawl dữ liệu từ trang web `https://fptshop.com.vn/dien-thoai?sort=ban-chay-nhat`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fptshop.png\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mục tiêu của chúng ta là lấy hết thông tin về các sản phẩm điện thoại bán chạy nhất mà chỉ xuất phát từ link ban đầu `https://fptshop.com.vn/dien-thoai?sort=ban-chay-nhat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trước hết cứ khởi tạo một project scrapy đã: (Mở cmd và chạy) <br/>\n",
    "`scrapy startproject fptshop`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngoài ra, còn các lệnh khác với ý nghĩa khác nhau, các bạn tham khảo bảng sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/commandline.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi tạo project xong chúng ta có cấu trúc thư mục như sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "fptshop/\n",
    "├── fptshop                         # nơi chứa code của dự án\n",
    "│   ├── __init__.py\n",
    "│   ├── items.py                    # nơi định nghĩa các trường dữ liệu cần lưu vào db\n",
    "│   ├── pipelines.py                # nơi xử lý các item trích xuất được và lưu vào db\n",
    "│   ├── settings.py                 # cấu hình thêm các phần mở rộng (middlewares) và các thông số cấu hình khác\n",
    "│   └── spiders                     # thư mục chứa các spider\n",
    "│       └── __init__.py\n",
    "└── scrapy.cfg                      # file cấu hình về deploy và settings của project`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tham khảo thêm tại đây: https://doc.scrapy.org/en/latest/intro/tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo việc của chúng ta là tạo ra một con bọ spider để sai nó đi vơ vét lyric nhạc cho mình.Tạo trong folder một file <b>fptshop_spider.py</b> và dán đoạn mã sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = 'mobile'\n",
    "    start_url = ['https://fptshop.com.vn/dien-thoai?sort=ban-chay-nhat']\n",
    "\n",
    "    def parse(self, response):\n",
    "        print(\"Hello spider\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mình sẽ giải thích đơn giản những thứ có trong file này :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>name</b>: Tên của con bọ, với mục đích khi run mình sẽ gọi tên để chỉ định con bọ (spider) nào sẽ đi crawl cho mình\n",
    "\n",
    "* <b>start_urls</b>: Có thể coi chính là địa chỉ bắt đầu cho spider, có thể là một list. Tại ví dụ này mình sẽ bắt đầu ở link các bài hát nhạc trẻ\n",
    "\n",
    "* <b>parse()</b>: Chính là nơi mình sẽ viết code để điều khiển spider làm việc cho mình (đi crawl link nhạc)\n",
    "\n",
    "Hiện giờ chúng ta đang xuất phát từ link . Mục tiêu của chúng ta là lấy được tất cả các site của các điện thoại trong link xuất phát và sẽ crawl dữ liệu của chúng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giao diện mỗi site:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/dt.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như các bạn thấy thì chúng ta sẽ phải lấy được địa chỉ của từng điện thoại, trước khi có thể động đến thông số chi tiết của nó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quay lại trang gốc và inspect để xem link của chúng, chúng ta cần lấy tất cả các link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/inspect.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khó khăn tiếp theo của chúng ta là những link chi tiết của bài nhạc không nằm hoàn toàn trên một trang, chúng giới hạn số lượng mỗi bài hiển thị:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/page.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như vậy để collect được hết link của từng điện thoại, chúng ta phải trải qua một bước nữa là phải có được link của tất cả các trang tab chứa các list bài hát cùng category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu chú ý thì bạn có thể để ý rằng là các trang tab này thay đổi tịnh tiếng địa chỉ url, ví dụ với ảnh phía trên chúng ta đang ở tab thứ 2 thì url sẽ có dạng là: `https://fptshop.com.vn/dien-thoai?sort=ban-chay-nhat&trang=2`.  Do đó tôi nảy ra một ý định là sẽ tìm tổng số tab và dùng một vòng for để tạo ra list các tab chứa những bài nhạc mình sẽ crawl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giờ công việc của chúng ta sẽ là:<br/>\n",
    "`\n",
    "Từ trang đích -> các trang tab\n",
    "Từ các trang tab -> trang chi tiết của điện thoại\n",
    "Từ trang chi tiết điện thoại -> crawl dữ liệu tương ứng`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các bạn hãy sử dụng command line shell để test xpath và css. Đầu tiên chúng ta cần lấy link trang cuối cùng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/get_xpath.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/9.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, thế là lấy được trang cuối cùng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giờ mình sẽ thêm tí code vào con spider để nó đi crawl nhé:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = 'mobile'\n",
    "    start_url = ['https://fptshop.com.vn/dien-thoai?sort=ban-chay-nhat']\n",
    "    home = 'https://fptshop.com.vn'\n",
    "\n",
    "        def parse(self, response):\n",
    "        finalPage = int(response.xpath('/html/body/section/div/div[2]/div[2]/div[4]/a[2]/@data-page').get())\n",
    "        url_page = 'https://fptshop.com.vn/dien-thoai?sort=ban-chay-nhat&trang=1'\n",
    "        for page in range(finalPage):\n",
    "            link = url_page.replace('1', str(page + 1))\n",
    "            yield scrapy.Request(link, callback=self.craw_mobile)\n",
    "\n",
    "    def craw_mobile(self, response):\n",
    "        link_mobile = response.css('.fs-lpil .fs-lpil-img::attr(href)').extract()\n",
    "        for link in link_mobile:\n",
    "            yield scrapy.Request(self.home + link, callback=self.save_file)\n",
    "\n",
    "    def save_file(self, response):\n",
    "        print(\"Test:\", response.css('.fs-tsright').get())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mình sẽ giải thích các hàm mới được thêm vào:\n",
    "\n",
    "* <b>yield scrapy.Request(link, callback=self.craw_mobile)</b>: Tạo request với 2 đối số là link là đường dẫn sẽ request tới và callback là hàm sẽ thực hiện khi request đến link được response\n",
    "\n",
    "* <b>parse()</b>: Từ link đích mình sẽ collect link của các tab chứa các điện thoại. ý tưởng ở đây là lấy số lượng tổng các tab sau đó dùng một vòng for để tạo ra các đường link tiếp theo mà spider sẽ thăm đến.\n",
    "\n",
    "* <b>crawl_mobile()</b>: Collect tất cả các trang điện thoại chi tiết và chuyển spider đến link và function tiếp theo\n",
    "\n",
    "* <b>save_file()</b>: Link response ở đây đã là link chi tiết của điện thoại và chứa thông tin mà chúng ta cần crawl. Chúng ta sẽ xét tiếp hàm này sau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Yield</b> tương tự như <b>return</b>, nhưng điểm khác biệt là nó sẽ lưu lại dữ liệu được yield, sau đó khi kết thúc nó sẽ trả về toàn bộ dữ liệu mà chương trình đã chạy. Bạn cần lưu ý là yield không lưu ở memory, mà được tạo ra và dùng trực tiếp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giờ thử ra lệnh cho spider hoạt động bằng câu lệnh:<br/>\n",
    "`scrapy crawl mobile`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/run_spider.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chạy ok. Và công việc tiếp theo của chúng ta là lấy tiếp các thông tin chi tiết của điện thoại lưu chúng vào cơ sở dữ liệu. Ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lưu dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>items.py</b> Chứa các định nghĩa thông tin mình muốn extract. <br/>\n",
    "Bạn hãy mở file <b>items.py</b> lên và chỉnh sửa như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class FptshopItem(scrapy.Item):\n",
    "    title = scrapy.Field()\n",
    "    screen = scrapy.Field()\n",
    "    ram = scrapy.Field()\n",
    "    link = scrapy.Field()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tức là chúng ta sẽ lấy tên điện thoại, màn hình, ram và link giới thiệu điện thoại này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quay lại sửa file <b>fptshop_spider.py</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from fptshop.items import FptshopItem\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = 'mobile'\n",
    "    start_urls = ['https://fptshop.com.vn/dien-thoai?sort=ban-chay-nhat']\n",
    "    home = 'https://fptshop.com.vn'\n",
    "\n",
    "    def parse(self, response):\n",
    "        finalPage = int(response.xpath('/html/body/section/div/div[2]/div[2]/div[4]/a[2]/@data-page').get())\n",
    "        url_page = 'https://fptshop.com.vn/dien-thoai?sort=ban-chay-nhat&trang=1'\n",
    "        for page in range(finalPage):\n",
    "            link = url_page.replace('1', str(page + 1))\n",
    "            yield scrapy.Request(link, callback=self.craw_mobile)\n",
    "\n",
    "    def craw_mobile(self, response):\n",
    "        link_mobile = response.css('.fs-lpil .fs-lpil-img::attr(href)').extract()\n",
    "        for link in link_mobile:\n",
    "            yield scrapy.Request(self.home + link, callback=self.save_file)\n",
    "\n",
    "    def save_file(self, response):\n",
    "        item = FptshopItem()\n",
    "        item['title'] = response.css('.fs-dttname ::text').get()\n",
    "        item['screen'] = response.xpath('/html/body/section/div/div[3]/div[2]/div[1]/div[2]/ul/li[1]/span/text()').get()\n",
    "        item['ram'] = response.xpath('/html/body/section/div/div[3]/div[2]/div[1]/div[2]/ul/li[4]/span/text()').get()\n",
    "        item['link'] = response.url\n",
    "        yield item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở command line, ta chạy lệnh: `scrapy crawl mobile -o output.json` để tạo ra file output.json lưu kết quả"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/kq2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu bạn muốn insert kết quả dạng khác như mysql, mylite3, ... thì có thể tìm hiểu thêm để cấu hình file pinelines.py. Trong phạm vi lấy data để phục vụ cho mô hình machine learning thì tôi thấy là không cần thiết nên tạm dừng tại đây. <br/>\n",
    "Tìm hiểu thêm: http://doc.scrapy.org/en/latest/topics/item-pipeline.html <br/>\n",
    "Source code ví dụ trên: <a href=\"./fptshop\">Tại đây</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
