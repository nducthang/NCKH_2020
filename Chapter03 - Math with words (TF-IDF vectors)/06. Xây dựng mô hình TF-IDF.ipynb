{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nội dung chính:\n",
    "1. Đặt vấn đề\n",
    "2. TF-IDF\n",
    "3. Thực hành tự xây dựng mô hình TF-IDF\n",
    "4. Consine Similarity\n",
    "5. Các biến thể của TF-IDF\n",
    "6. Sử dụng sklearn để build mô hình TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở các bài viết trước, chúng ta đã tìm hiểu qua 2 mô hình word embbeding (nhúng từ) cơ bản nhất là one-hot endcoding và bag of word. Trong bài này chúng ta sẽ tìm hiểu thêm 1 mô hình nữa phổ biến hơn nhưng vẫn đơn giản đó là TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đặt vấn đề?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoW là phương pháp đếm số từ. Vậy Bow có thực sự hiệu quả không?<br/>\n",
    "Ví dụ ta có 2 văn bản, một văn bản có tổng số từ là 20 từ nhưng có đến 10 từ là \"chó\". Con văn bản còn lại có đến 10000 từ và có 2000 từ là \"chó\". Nếu theo phương pháp BoW thì rõ ràng văn bản thứ 2 là từ \"chó\" có tầm quan trọng hơn.<br/>\n",
    "Tuy nhiên, không phải như vậy, với văn bản thứ nhất thì từ \"chó\" chiếm đến 50% số từ của văn bản. Còn văn bản thứ 2 thì chỉ chiếm 20%. Do vậy, \"chó\" ở văn bản thứ nhất có tầm ảnh hưởng lớn hơn so với \"chó\" của văn bản thứ 2. Từ đó, chúng ta thấy rằng, BoW chưa thể hiện đúng được tầm ảnh hưởng của 1 từ trong văn bản. Vì thế, TF-IDF ra đời và khắc phục điều này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>tf–idf</b>, viết tắt của thuật ngữ tiếng Anh <i>term frequency – inverse document frequency</i>, của một từ là một con số thu được qua thống kê thể hiện mức độ quan trọng của từ này trong một văn bản, mà bản thân văn bản đang xét nằm trong một tập hợp các văn bản. Giá trị cao thể hiện độ quan trọng cao và nó phụ thuộc vào số lần từ xuất hiện trong văn bản nhưng bù lại bởi tần suất của từ đó trong tập dữ liệu. Một vài biến thể của tf-idf thường được sử dụng trong các hệ thống tìm kiếm như một công cụ chính để đánh giá và sắp xếp văn bản dựa vào truy vấn của người dùng.  Tf-idf cũng được sử dụng để lọc những từ stopwords trong các bài toán như tóm tắt văn bản và phân loại văn bản."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF là gì?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>TF</b>: Term Frequency (Tần suất xuất hiện của từ) là số lần từ xuất hiện trong văn bản. Term frequency thường được chia cho độ dài văn bản (Tổng số từ trong một văn bản)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$tf(t,d) = \\frac{f(t,d)}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong đó:\n",
    "    * tf(t, d): tần suất xuất hiện từ t trong văn bản d\n",
    "    * f(t,d): Số lần xuất hiện của từ t trong văn bản d\n",
    "    * n: Tổng số từ văn bản d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDF là gì?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse Document Frequency(Nghịch đảo tần suất của văn bản), giúp đánh giá tầm quan trọng của một từ . Khi tính toán TF , tất cả các từ được coi như có độ quan trọng bằng nhau. Nhưng  một số từ như “is”, “of” và “that” thường xuất hiện rất nhiều lần nhưng độ quan trọng là không cao. Như thế chúng ta cần giảm độ quan trọng của những từ này xuống."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/idf.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong đó:\n",
    "    * idf(t, D): giá trị idf của từ t trong tập văn bản.\n",
    "    * |D|: Tổng số văn bản trong tập D.\n",
    "    * |{d ∈ D : t ∈ d}|: thể hiện số văn bản trong tập D có chứa từ t."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cơ số logarit trong công thức này không thay đổi giá trị idf của từ mà chỉ thu hẹp khoảng giá trị của từ đó. Vì thay đổi cơ số sẽ dẫn đến việc giá trị của các từ thay đổi bởi một số nhất định và tỷ lệ giữa các trọng lượng với nhau sẽ không thay đổi. (nói cách khác, thay đổi cơ số sẽ không ảnh hưởng đến tỷ lệ giữa các giá trị IDF). Việc sử dụng logarit nhằm giúp giá trị tf-idf của một từ nhỏ hơn, do chúng ta có công thức tính tf-idf của một từ trong 1 văn bản là tích của tf và idf của từ đó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cụ thể, chúng ta có công thức tính <b>tf-idf</b> hoàn chỉnh như sau: <font color=\"blue\"><b>tfidf(t, d, D) = tf(t, d) x idf(t, D)</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Những từ có giá trị TF-IDF cao là những từ xuất hiện nhiều trong văn bản này, và xuất hiện ít trong các văn bản khác. Việc này giúp lọc ra những từ phổ biến và giữ lại những từ có giá trị cao (từ khoá của văn bản đó)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ví dụ:</b> một văn bản chưa 100 từ mà từ “cat” xuất hiện 3 lần . Term frequency cho từ cat này là (3/100) = 0.03 . Giả sử , chúng ta có 10 triệu văn bản và từ “cat” xuất hiện trong một nghìn văn bản . Như thế , idf được dính là  log(10,000,000 / 1,000) = 4. Như thế , tf-idf của từ “cat” trong văn bản này sẽ là : 0.03 * 4 = 0.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thực hành xây dựng mô hình TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Năm 1998, Google xử lý trung bình 9800 tìm kiếm mỗi ngày. Năm 2016, số lượng tìm kiếm trung bình mỗi ngày trên Google là hơn 9 tỉ lượt tìm kiếm. Biểu đồ dưới đây cho ta thông tin chi tiết về mức tăng tương về số lần tìm kiếm trên Google."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/Google.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lý do chính trong thành công của Google chính là thuật toán PageRank. Thuật toán PageRank quyết định xem danh tiếng và độ tin cậy của một website như thế nào. Nhưng bên cạnh đó còn có một phần khác nữa đã tạo nên thành công của Google. Cụm từ tìm kiếm (query) do người dùng nhập vào cần được xử lý để matching với các tài liệu trên Internet. Bài viết sẽ tập trung vào phần thứ hai này. Tôi sẽ tạo ra ba document (tài liệu) để mô tả phần matching này hoạt động như thế nào."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"Người lên ngựa kẻ chia bào. Rừng phong thu đã nhóm màu quan san\"\n",
    "doc2 = \"Ô hay buồn vương ây ngô đồng. Vàng rơi vàng rơi thu mênh mông\"\n",
    "doc3 = \"Một chiều vê bến sông thu. Nghe tin em cưới á cái đù\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy tưởng tượng rằng chúng ta đang tìm kiếm trong một data set hoặc trên Internet ( và giả sử Internet chỉ có 3 tài liệu này) với từ khóa chúng ta nhập là: <b>sông thu</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tìm kiếm của chúng ta là một free text query, nghĩa là các từ khóa được gõ một cách tùy ý trong ô tìm kiếm và không có sự kết nối giữa các từ với nhau. Theo cách tìm kiếm này, nếu chúng ta nhập sông thu hay thu sông thì thuật toán cũng shows cho chúng ta các kết quả giống nhau.<br/>\n",
    "\n",
    "Hãy đi vào chi tiết từng bước để xem phần matching tìm kiếm này hoạt động như thế nào."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bước 1: Tearm Frequency (TF - hay tần số xuất hiện của một từ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Văn bản 1: người lên ngựa kẻ chia bào  rừng phong thu đã nhóm màu quan san\n",
      "Văn bản 2: ô hay buồn vương ây ngô đồng  vàng rơi vàng rơi thu mênh mông\n",
      "Văn bản 3: một chiều vê bến sông thu  nghe tin em cưới á cái đù\n"
     ]
    }
   ],
   "source": [
    "# Tiền xử lý: loại bỏ dấu chấm và chuyển về chữ thường\n",
    "doc1 = doc1.replace(\".\",\" \").lower()\n",
    "doc2 = doc2.replace(\".\",\" \").lower()\n",
    "doc3 = doc3.replace(\".\",\" \").lower()\n",
    "print(\"Văn bản 1:\", doc1)\n",
    "print(\"Văn bản 2:\", doc2)\n",
    "print(\"Văn bản 3:\", doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word1: ['người', 'lên', 'ngựa', 'kẻ', 'chia', 'bào', 'rừng', 'phong', 'thu', 'đã', 'nhóm', 'màu', 'quan', 'san']\n",
      "Word2: ['ô', 'hay', 'buồn', 'vương', 'ây', 'ngô', 'đồng', 'vàng', 'rơi', 'vàng', 'rơi', 'thu', 'mênh', 'mông']\n",
      "Word3: ['một', 'chiều', 'vê', 'bến', 'sông', 'thu', 'nghe', 'tin', 'em', 'cưới', 'á', 'cái', 'đù']\n"
     ]
    }
   ],
   "source": [
    "# Cắt lấy từ (tokenizer)\n",
    "word1 = doc1.split()\n",
    "word2 = doc2.split()\n",
    "word3 = doc3.split()\n",
    "print(\"Word1:\", word1)\n",
    "print(\"Word2:\", word2)\n",
    "print(\"Word3:\", word3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'người': 1, 'lên': 1, 'ngựa': 1, 'kẻ': 1, 'chia': 1, 'bào': 1, 'rừng': 1, 'phong': 1, 'thu': 1, 'đã': 1, 'nhóm': 1, 'màu': 1, 'quan': 1, 'san': 1})\n",
      "Counter({'vàng': 2, 'rơi': 2, 'ô': 1, 'hay': 1, 'buồn': 1, 'vương': 1, 'ây': 1, 'ngô': 1, 'đồng': 1, 'thu': 1, 'mênh': 1, 'mông': 1})\n",
      "Counter({'một': 1, 'chiều': 1, 'vê': 1, 'bến': 1, 'sông': 1, 'thu': 1, 'nghe': 1, 'tin': 1, 'em': 1, 'cưới': 1, 'á': 1, 'cái': 1, 'đù': 1})\n"
     ]
    }
   ],
   "source": [
    "# Đếm số lần xuất hiện\n",
    "from collections import Counter\n",
    "word_dict1 = Counter(word1)\n",
    "word_dict2 = Counter(word2)\n",
    "word_dict3 = Counter(word3)\n",
    "print(word_dict1)\n",
    "print(word_dict2)\n",
    "print(word_dict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính toán TF\n",
    "def computeTF(word_dict, words):\n",
    "    tf_dict = {}\n",
    "    words_count = len(words)\n",
    "    for word, count in word_dict.items():\n",
    "        tf_dict[word] = count/float(words_count)\n",
    "    return tf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_doc1 = computeTF(word_dict1, word1)\n",
    "tf_doc2 = computeTF(word_dict2, word2)\n",
    "tf_doc3 = computeTF(word_dict3, word3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'người': 0.07142857142857142,\n",
       " 'lên': 0.07142857142857142,\n",
       " 'ngựa': 0.07142857142857142,\n",
       " 'kẻ': 0.07142857142857142,\n",
       " 'chia': 0.07142857142857142,\n",
       " 'bào': 0.07142857142857142,\n",
       " 'rừng': 0.07142857142857142,\n",
       " 'phong': 0.07142857142857142,\n",
       " 'thu': 0.07142857142857142,\n",
       " 'đã': 0.07142857142857142,\n",
       " 'nhóm': 0.07142857142857142,\n",
       " 'màu': 0.07142857142857142,\n",
       " 'quan': 0.07142857142857142,\n",
       " 'san': 0.07142857142857142}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ô': 0.07142857142857142,\n",
       " 'hay': 0.07142857142857142,\n",
       " 'buồn': 0.07142857142857142,\n",
       " 'vương': 0.07142857142857142,\n",
       " 'ây': 0.07142857142857142,\n",
       " 'ngô': 0.07142857142857142,\n",
       " 'đồng': 0.07142857142857142,\n",
       " 'vàng': 0.14285714285714285,\n",
       " 'rơi': 0.14285714285714285,\n",
       " 'thu': 0.07142857142857142,\n",
       " 'mênh': 0.07142857142857142,\n",
       " 'mông': 0.07142857142857142}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'một': 0.07692307692307693,\n",
       " 'chiều': 0.07692307692307693,\n",
       " 'vê': 0.07692307692307693,\n",
       " 'bến': 0.07692307692307693,\n",
       " 'sông': 0.07692307692307693,\n",
       " 'thu': 0.07692307692307693,\n",
       " 'nghe': 0.07692307692307693,\n",
       " 'tin': 0.07692307692307693,\n",
       " 'em': 0.07692307692307693,\n",
       " 'cưới': 0.07692307692307693,\n",
       " 'á': 0.07692307692307693,\n",
       " 'cái': 0.07692307692307693,\n",
       " 'đù': 0.07692307692307693}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_doc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bước 2: Inverse Document Frequency (IDF – tần số nghịch của một từ trong một data set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mục đích chính của việc tìm kiếm văn bản là tìm ra những văn bản trong một data set (hoặc Internet nói chung) có nội dung liên quan nhất với từ tìm kiếm của người dùng. Ở bước 1 (TF), tất cả các từ đều được đánh giá quan trọng ngang nhau.Tuy nhiên, trong thực tế thì có một số từ xuất hiện quá nhiều và không có vai trò quyết định trong việc tìm ra các văn bản có nội dung liên quan với chủ đề mà người dùng tìm kiếm (trong tiếng Anh thì những từ xuất hiện nhiều và ít quan trọng là the, a, he, she, etc…). Chúng ta cần tìm ra một cách để làm giảm trọng số của những từ xuất hiện quá thường xuyên (trên Internet) và tăng trọng số của những từ ít xuất hiện (trên Internet) hơn. Và công cụ toán học Logarithm (Lôgarit) sẽ giúp chúng ta làm được điều này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính toán IDF\n",
    "import math\n",
    "def computeIDF(word_dicts):\n",
    "    idf_dict = {}\n",
    "    N = len(word_dicts)\n",
    "    keys = set().union(*word_dicts)\n",
    "    \n",
    "    # Tạo danh sách keys\n",
    "    idf_dict = dict.fromkeys(keys, 0)\n",
    "    \n",
    "    for doc in word_dicts: # duyệt từng document\n",
    "        for word, val in doc.items(): # duyệt từng từ trong document\n",
    "            if val > 0:\n",
    "                idf_dict[word] += 1\n",
    "                \n",
    "    for word, val in idf_dict.items():\n",
    "        idf_dict[word] = math.log(N / float(val))\n",
    "        \n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([word_dict1, word_dict2, word_dict3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quan': 1.0986122886681098,\n",
       " 'bào': 1.0986122886681098,\n",
       " 'hay': 1.0986122886681098,\n",
       " 'vê': 1.0986122886681098,\n",
       " 'một': 1.0986122886681098,\n",
       " 'mênh': 1.0986122886681098,\n",
       " 'san': 1.0986122886681098,\n",
       " 'tin': 1.0986122886681098,\n",
       " 'sông': 1.0986122886681098,\n",
       " 'ngựa': 1.0986122886681098,\n",
       " 'ngô': 1.0986122886681098,\n",
       " 'ây': 1.0986122886681098,\n",
       " 'á': 1.0986122886681098,\n",
       " 'cái': 1.0986122886681098,\n",
       " 'thu': 0.0,\n",
       " 'đồng': 1.0986122886681098,\n",
       " 'cưới': 1.0986122886681098,\n",
       " 'đù': 1.0986122886681098,\n",
       " 'buồn': 1.0986122886681098,\n",
       " 'người': 1.0986122886681098,\n",
       " 'chia': 1.0986122886681098,\n",
       " 'chiều': 1.0986122886681098,\n",
       " 'đã': 1.0986122886681098,\n",
       " 'rơi': 1.0986122886681098,\n",
       " 'lên': 1.0986122886681098,\n",
       " 'màu': 1.0986122886681098,\n",
       " 'vương': 1.0986122886681098,\n",
       " 'phong': 1.0986122886681098,\n",
       " 'nhóm': 1.0986122886681098,\n",
       " 'vàng': 1.0986122886681098,\n",
       " 'nghe': 1.0986122886681098,\n",
       " 'rừng': 1.0986122886681098,\n",
       " 'bến': 1.0986122886681098,\n",
       " 'mông': 1.0986122886681098,\n",
       " 'em': 1.0986122886681098,\n",
       " 'ô': 1.0986122886681098,\n",
       " 'kẻ': 1.0986122886681098}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bên dưới là bảng IDF của tất cả các từ trong data set. Trong đó từ <b>thu</b> xuất hiện trong cả 3 văn bản nên nó sẽ có điểm số IDF thấp hơn so với các từ chỉ xuất hiện một văn bản."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bước 3: Tính TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tf, idf):\n",
    "    tf_idf = {}\n",
    "    for word, val in tf.items():\n",
    "        tf_idf[word] = val*idf[word]\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_doc1 = computeTFIDF(tf_doc1, idfs)\n",
    "tf_idf_doc2 = computeTFIDF(tf_doc2, idfs)\n",
    "tf_idf_doc3 = computeTFIDF(tf_doc3, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'người': 0.07847230633343641,\n",
       " 'lên': 0.07847230633343641,\n",
       " 'ngựa': 0.07847230633343641,\n",
       " 'kẻ': 0.07847230633343641,\n",
       " 'chia': 0.07847230633343641,\n",
       " 'bào': 0.07847230633343641,\n",
       " 'rừng': 0.07847230633343641,\n",
       " 'phong': 0.07847230633343641,\n",
       " 'thu': 0.0,\n",
       " 'đã': 0.07847230633343641,\n",
       " 'nhóm': 0.07847230633343641,\n",
       " 'màu': 0.07847230633343641,\n",
       " 'quan': 0.07847230633343641,\n",
       " 'san': 0.07847230633343641}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ô': 0.07847230633343641,\n",
       " 'hay': 0.07847230633343641,\n",
       " 'buồn': 0.07847230633343641,\n",
       " 'vương': 0.07847230633343641,\n",
       " 'ây': 0.07847230633343641,\n",
       " 'ngô': 0.07847230633343641,\n",
       " 'đồng': 0.07847230633343641,\n",
       " 'vàng': 0.15694461266687282,\n",
       " 'rơi': 0.15694461266687282,\n",
       " 'thu': 0.0,\n",
       " 'mênh': 0.07847230633343641,\n",
       " 'mông': 0.07847230633343641}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'một': 0.08450863758985461,\n",
       " 'chiều': 0.08450863758985461,\n",
       " 'vê': 0.08450863758985461,\n",
       " 'bến': 0.08450863758985461,\n",
       " 'sông': 0.08450863758985461,\n",
       " 'thu': 0.0,\n",
       " 'nghe': 0.08450863758985461,\n",
       " 'tin': 0.08450863758985461,\n",
       " 'em': 0.08450863758985461,\n",
       " 'cưới': 0.08450863758985461,\n",
       " 'á': 0.08450863758985461,\n",
       " 'cái': 0.08450863758985461,\n",
       " 'đù': 0.08450863758985461}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_doc3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame([tf_idf_doc1, tf_idf_doc2, tf_idf_doc3]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>người</th>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lên</th>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ngựa</th>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kẻ</th>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chia</th>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bào</th>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rừng</th>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phong</th>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thu</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>đã</th>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nhóm</th>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>màu</th>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quan</th>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ô</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hay</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buồn</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vương</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ây</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ngô</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>đồng</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vàng</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156945</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rơi</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156945</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mênh</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mông</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078472</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>một</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiều</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vê</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bến</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sông</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nghe</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>em</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cưới</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>á</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cái</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>đù</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2\n",
       "người  0.078472       NaN       NaN\n",
       "lên    0.078472       NaN       NaN\n",
       "ngựa   0.078472       NaN       NaN\n",
       "kẻ     0.078472       NaN       NaN\n",
       "chia   0.078472       NaN       NaN\n",
       "bào    0.078472       NaN       NaN\n",
       "rừng   0.078472       NaN       NaN\n",
       "phong  0.078472       NaN       NaN\n",
       "thu    0.000000  0.000000  0.000000\n",
       "đã     0.078472       NaN       NaN\n",
       "nhóm   0.078472       NaN       NaN\n",
       "màu    0.078472       NaN       NaN\n",
       "quan   0.078472       NaN       NaN\n",
       "san    0.078472       NaN       NaN\n",
       "ô           NaN  0.078472       NaN\n",
       "hay         NaN  0.078472       NaN\n",
       "buồn        NaN  0.078472       NaN\n",
       "vương       NaN  0.078472       NaN\n",
       "ây          NaN  0.078472       NaN\n",
       "ngô         NaN  0.078472       NaN\n",
       "đồng        NaN  0.078472       NaN\n",
       "vàng        NaN  0.156945       NaN\n",
       "rơi         NaN  0.156945       NaN\n",
       "mênh        NaN  0.078472       NaN\n",
       "mông        NaN  0.078472       NaN\n",
       "một         NaN       NaN  0.084509\n",
       "chiều       NaN       NaN  0.084509\n",
       "vê          NaN       NaN  0.084509\n",
       "bến         NaN       NaN  0.084509\n",
       "sông        NaN       NaN  0.084509\n",
       "nghe        NaN       NaN  0.084509\n",
       "tin         NaN       NaN  0.084509\n",
       "em          NaN       NaN  0.084509\n",
       "cưới        NaN       NaN  0.084509\n",
       "á           NaN       NaN  0.084509\n",
       "cái         NaN       NaN  0.084509\n",
       "đù          NaN       NaN  0.084509"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy nhớ rằng mục đích của chúng ta là đi tìm văn bản có nội dung liên quan nhất cho cụm từ tìm kiếm : <b>sông thu</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1         NaN\n",
       "2    0.084509\n",
       "Name: sông, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[\"sông\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "Name: thu, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[\"thu\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vậy tính xong TF-IDF, ta cần phải có 1 công thức để đo mức độ tương quan. Vì vậy chúng ta cung tìm hiểu phần sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consine simalarity là 1 công thức đo mức độ tương đồng giữa 2 vector trong một không gian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$similarity=cos(\\theta)=\\frac{A.B}{||A||.||B||}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta mô tả mỗi document như là một vector. Một data set được xem như là một tập hợp các vector trong một không gian vector. Mỗi từ trong không gian vector sẽ có trục của riêng nó. Bằng cách sử dụng công thức phía trên, chúng ta có thể tìm ra độ tương đồng của bất kì tài liệu nào."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector chỉ làm việc với con số. Trong bài viết này chúng ta đang làm việc với văn bản. Đó là lý do tại sao chúng ta sử dụng TF – IDF để chuyển đổi từ ngữ văn bản thành số để có thể biểu diễn chúng ở dạng vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cụm từ tìm kiếm của người dùng cũng được xem là một vector. Chúng ta tính giá trị TF * IDF cho cụm từ truy vấn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sông': 0.5493061443340549, 'thu': 0.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_user = {}\n",
    "tf_idf_user[\"sông\"] = 0.5*idfs[\"sông\"]\n",
    "tf_idf_user[\"thu\"] = 0.5*idfs[\"thu\"]\n",
    "tf_idf_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.5 ở đây tức là cụm từ tìm kiếm có 2 từ \"sông thu\" nên tf_user[\"sông\"] = tf_user[\"thu\"] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ chúng ta hãy tính cosine similarity (tương đồng cosine) giữa cụm từ tìm kiếm (Query) và các Document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def consine_sim(vec1, vec2):\n",
    "    \"\"\" Let's convert our dictionaries to lists for easier matching \"\"\"\n",
    "    vec1 = [val for val in vec1.values()]\n",
    "    vec2 = [val for val in vec2.values()]\n",
    "    \n",
    "    dot_prod = 0\n",
    "    for i,v in enumerate(vec1):\n",
    "        dot_prod += v*vec2[i]\n",
    "    \n",
    "    mag_1 = math.sqrt(sum([x**2 for x in vec1]))\n",
    "    mag_2 = math.sqrt(sum([x**2 for x in vec2]))\n",
    "    \n",
    "    return dot_prod/(mag_1*mag_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec1: {'sông': 0.5493061443340549, 'thu': 0.0}\n",
      "vec2: {'sông': 0.0, 'thu': 0.0}\n"
     ]
    }
   ],
   "source": [
    "vec1 = tf_idf_user\n",
    "vec2 = {}\n",
    "vec2[\"sông\"] = 0.0 # do trong tf_idf_doc1 không có từ sông\n",
    "vec2[\"thu\"] = tf_idf_doc1[\"thu\"]\n",
    "print(\"vec1:\",vec1)\n",
    "print(\"vec2:\",vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ tính sự tương đồng giữa từ khoá người dùng và document1 thành bài toán trở thành tính độ tương đồng giữa vec1 = (0.549, 0) và vec2=(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lỗi chia cho 0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    consine_sim(vec1, vec2)\n",
    "except:\n",
    "    print(\"Lỗi chia cho 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lỗi. Ta thử tính với document3 xem sao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec1: {'sông': 0.5493061443340549, 'thu': 0.0}\n",
      "vec2: {'sông': 0.08450863758985461, 'thu': 0.0}\n"
     ]
    }
   ],
   "source": [
    "vec2_3 = {}\n",
    "vec2_3[\"sông\"] = tf_idf_doc3[\"sông\"]\n",
    "vec2_3[\"thu\"] = tf_idf_doc3[\"thu\"]\n",
    "print(\"vec1:\",vec1)\n",
    "print(\"vec2:\",vec2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consine_sim(vec1, vec2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vậy là có cái tính được cái không? Một số bị lỗi chia cho 0. Và để khắc phục điều này người ta có một số phương pháp cải tiến TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các biến thể của TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với bài toán trên, ta thấy từ thu xuất hiện ở cả 3 văn bản và idf[\"thu\"]=0 và gây ra hiện tượng ta không thể tính được consine similarity. Vì vậy ý tưởng cơ bản nhất là ta điều chỉnh công thức tính idf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF(thu) = 1 + ln(Tổng số văn bản trong data set/Số văn bản chứa từ thu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính toán IDF\n",
    "import math\n",
    "def computeIDF_new(word_dicts):\n",
    "    idf_dict = {}\n",
    "    N = len(word_dicts)\n",
    "    keys = set().union(*word_dicts)\n",
    "    \n",
    "    # Tạo danh sách keys\n",
    "    idf_dict = dict.fromkeys(keys, 0)\n",
    "    \n",
    "    for doc in word_dicts: # duyệt từng document\n",
    "        for word, val in doc.items(): # duyệt từng từ trong document\n",
    "            if val > 0:\n",
    "                idf_dict[word] += 1\n",
    "                \n",
    "    for word, val in idf_dict.items():\n",
    "        idf_dict[word] = 1 + math.log(N / float(val)) # Thay đổi tại đây\n",
    "        \n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs_new = computeIDF_new([word_dict1, word_dict2, word_dict3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quan': 2.09861228866811,\n",
       " 'bào': 2.09861228866811,\n",
       " 'hay': 2.09861228866811,\n",
       " 'vê': 2.09861228866811,\n",
       " 'một': 2.09861228866811,\n",
       " 'mênh': 2.09861228866811,\n",
       " 'san': 2.09861228866811,\n",
       " 'tin': 2.09861228866811,\n",
       " 'sông': 2.09861228866811,\n",
       " 'ngựa': 2.09861228866811,\n",
       " 'ngô': 2.09861228866811,\n",
       " 'ây': 2.09861228866811,\n",
       " 'á': 2.09861228866811,\n",
       " 'cái': 2.09861228866811,\n",
       " 'thu': 1.0,\n",
       " 'đồng': 2.09861228866811,\n",
       " 'cưới': 2.09861228866811,\n",
       " 'đù': 2.09861228866811,\n",
       " 'buồn': 2.09861228866811,\n",
       " 'người': 2.09861228866811,\n",
       " 'chia': 2.09861228866811,\n",
       " 'chiều': 2.09861228866811,\n",
       " 'đã': 2.09861228866811,\n",
       " 'rơi': 2.09861228866811,\n",
       " 'lên': 2.09861228866811,\n",
       " 'màu': 2.09861228866811,\n",
       " 'vương': 2.09861228866811,\n",
       " 'phong': 2.09861228866811,\n",
       " 'nhóm': 2.09861228866811,\n",
       " 'vàng': 2.09861228866811,\n",
       " 'nghe': 2.09861228866811,\n",
       " 'rừng': 2.09861228866811,\n",
       " 'bến': 2.09861228866811,\n",
       " 'mông': 2.09861228866811,\n",
       " 'em': 2.09861228866811,\n",
       " 'ô': 2.09861228866811,\n",
       " 'kẻ': 2.09861228866811}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_doc1_new = computeTFIDF(tf_doc1, idfs_new)\n",
    "tf_idf_doc2_new = computeTFIDF(tf_doc2, idfs_new)\n",
    "tf_idf_doc3_new = computeTFIDF(tf_doc3, idfs_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'người': 0.14990087776200786,\n",
       " 'lên': 0.14990087776200786,\n",
       " 'ngựa': 0.14990087776200786,\n",
       " 'kẻ': 0.14990087776200786,\n",
       " 'chia': 0.14990087776200786,\n",
       " 'bào': 0.14990087776200786,\n",
       " 'rừng': 0.14990087776200786,\n",
       " 'phong': 0.14990087776200786,\n",
       " 'thu': 0.07142857142857142,\n",
       " 'đã': 0.14990087776200786,\n",
       " 'nhóm': 0.14990087776200786,\n",
       " 'màu': 0.14990087776200786,\n",
       " 'quan': 0.14990087776200786,\n",
       " 'san': 0.14990087776200786}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_doc1_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sông': 1.049306144334055, 'thu': 0.5}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_user_new = {}\n",
    "tf_idf_user_new[\"sông\"] = 0.5*idfs_new[\"sông\"]\n",
    "tf_idf_user_new[\"thu\"] = 0.5*idfs_new[\"thu\"]\n",
    "tf_idf_user_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sông': 0.0, 'thu': 0.07142857142857142}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_doc1_new = {}\n",
    "vec_doc1_new[\"sông\"] = 0.0\n",
    "vec_doc1_new[\"thu\"] = tf_idf_doc1_new[\"thu\"]\n",
    "vec_doc1_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sông': 0.0, 'thu': 0.07142857142857142}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_doc2_new = {}\n",
    "vec_doc2_new[\"sông\"] = 0.0\n",
    "vec_doc2_new[\"thu\"] = tf_idf_doc2_new[\"thu\"]\n",
    "vec_doc2_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sông': 0.16143171451293153, 'thu': 0.07692307692307693}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_doc3_new = {}\n",
    "vec_doc3_new[\"sông\"] = tf_idf_doc3_new[\"sông\"]\n",
    "vec_doc3_new[\"thu\"] = tf_idf_doc3_new[\"thu\"]\n",
    "vec_doc3_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.430165282498796"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consine_sim(tf_idf_user_new, vec_doc1_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.430165282498796"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consine_sim(tf_idf_user_new, vec_doc2_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consine_sim(tf_idf_user_new, vec_doc3_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta có thể thấy là Document 3 có score cao nhất bằng 1. Lý do là vì Document 3 chứa đồng thời cả hai từ sông và thu. Điều này có nghĩa là khi người dùng tìm kiếm với cụm từ là sông thu thì thuật toán sẽ trả về tài liệu có độ tương đồng cosine lớn nhất với nó là Document 3. Tất nhiên, mô hình trên là tôi xây dựng tay nên chưa tối ưu, khi làm bài toán thực tế, chúng ta sẽ thường sử dụng thư viện hỗ trợ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngoài ra chúng ta có bảng sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/table.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sử dụng sklearn để build mô hình TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ có rất nhiều packet hỗ trợ chúng ta tự động hoá. Như là scikit-learn.Tại đây, bạn có thể sử dụng sklearn để xây dựng một ma trận TF-IDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['người lên ngựa kẻ chia bào  rừng phong thu đã nhóm màu quan san',\n",
       " 'ô hay buồn vương ây ngô đồng  vàng rơi vàng rơi thu mênh mông',\n",
       " 'một chiều vê bến sông thu  nghe tin em cưới á cái đù']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [doc1, doc2, doc3]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buồn',\n",
       " 'bào',\n",
       " 'bến',\n",
       " 'chia',\n",
       " 'chiều',\n",
       " 'cái',\n",
       " 'cưới',\n",
       " 'em',\n",
       " 'hay',\n",
       " 'kẻ',\n",
       " 'lên',\n",
       " 'màu',\n",
       " 'mênh',\n",
       " 'mông',\n",
       " 'một',\n",
       " 'nghe',\n",
       " 'ngô',\n",
       " 'người',\n",
       " 'ngựa',\n",
       " 'nhóm',\n",
       " 'phong',\n",
       " 'quan',\n",
       " 'rơi',\n",
       " 'rừng',\n",
       " 'san',\n",
       " 'sông',\n",
       " 'thu',\n",
       " 'tin',\n",
       " 'vàng',\n",
       " 'vê',\n",
       " 'vương',\n",
       " 'á',\n",
       " 'ây',\n",
       " 'ô',\n",
       " 'đã',\n",
       " 'đù',\n",
       " 'đồng']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon = sorted(set(word1+word2+word3))\n",
    "lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buồn', 'bào', 'bến', 'chia', 'chiều', 'cái', 'cưới', 'em', 'hay', 'kẻ', 'lên', 'màu', 'mênh', 'mông', 'một', 'nghe', 'ngô', 'người', 'ngựa', 'nhóm', 'phong', 'quan', 'rơi', 'rừng', 'san', 'sông', 'thu', 'tin', 'vàng', 'vê', 'vương', 'ây', 'đã', 'đù', 'đồng']\n",
      "[[0.    0.275 0.    0.275 0.    0.    0.    0.    0.    0.275 0.275 0.275\n",
      "  0.    0.    0.    0.    0.    0.275 0.275 0.275 0.275 0.275 0.    0.275\n",
      "  0.275 0.    0.131 0.    0.    0.    0.    0.    0.275 0.    0.   ]\n",
      " [0.248 0.    0.    0.    0.    0.    0.    0.    0.248 0.    0.    0.\n",
      "  0.248 0.248 0.    0.    0.248 0.    0.    0.    0.    0.    0.496 0.\n",
      "  0.    0.    0.118 0.    0.496 0.    0.248 0.248 0.    0.    0.248]\n",
      " [0.    0.    0.298 0.    0.298 0.298 0.298 0.298 0.    0.    0.    0.\n",
      "  0.    0.    0.298 0.298 0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.298 0.142 0.298 0.    0.298 0.    0.    0.    0.298 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(smooth_idf=False) # Mặc định là True\n",
    "# Khi smooth_idf=False thì idf(t) = log [ n / df(t) ] + 1\n",
    "# Còn True thì idf(t) = log [ n / (df(t) + 1) ]).\n",
    "model = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(model.todense().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mô hình của sklearn loại bỏ từ <b>á</b> và <b>ô</b> khỏi lexicon của chúng ta vì thư viện này cho rằng các từ 1 ký tự không đem lại ý nghĩa. Vì vậy kết quả tính mới hơi khác mô hình tự thiết lập của chúng ta, các bạn có thể thử loại bỏ 2 từ trên và tính toán lại để kiếm tra lại kết quả tự tính và của sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem thêm: https://github.com/scikit-learn/scikit-learn/blob/7a636f0cc5f63aaab2d0e556fec46989465934aa/sklearn/feature_extraction/text.py#L1140"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
