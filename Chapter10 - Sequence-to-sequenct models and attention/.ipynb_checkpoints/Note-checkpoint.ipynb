{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chương này bao gồm:\n",
    "Ánh xạ một chuỗi văn bản này sang chuỗi văn bản khác với mạng neural.\n",
    "Hiểu về mô hình seq2seq và khác biệt như thế nào với những mô hình đã học.\n",
    "Sử dụng kiến trúc mô hình encoder-decoder cho dịch máy và chat\n",
    "Huấn luyện một mô hình với cơ chế attention trong một chuỗi\n",
    "# 1. Kiến trúc Encoder-decoder\n",
    "## 1.1 Decoding thought\n",
    "Hãy tưởng tượng bạn muốn phát triển một mô hình dịch từ tiếng Anh sang tiếng Đức. Bạn muốn ánh xạ chuỗi ký tự hoặc một từ với một chuỗi hoặc ký tự khác. Trước đây bạn đã biết cách xây dựng mô hình để dự đoán một phần tử ở bước thời gian t dựa vào bước thời gian trước đó là t-1. Nhưng trực tiếp sử dụng một LSTM để ánh xạ một ngôn ngữ này sang ngôn ngữ khác nhanh chóng gặp sự cố, vì với LSTM thì chuỗi đầu vào và đầu ra phải giống nhau về độ dài. Bạn mong muốn một mô hình tổng quát hơn.\n",
    "\n",
    "Mạng sequence-to-sequence, đối khi được gọi tắt là *seq2seq* giải quyết vấn đề này bằng cách tạo một biểu diễn đầu vào dưới dạng một vector suy nghĩ *throght vector*. Mô hình seq2seq sử dụng vector đó, thỉnh thoảng gọi là *context vector* như là một điểm bắt đầu cho một mạng thứ 2 nhận một tập các đầu vào khác nhau để sinh chuỗi đầu ra.\n",
    "\n",
    "**THOUGHT VECTOR:** Hãy nhớ khi bạn phát hiện ra word vector? Word vector là biểu diễn một từ thành một vector có độ dài cố định. Các từ có nghĩa tương tự nhau thì gần nhau trong không gian vector này. Một thought vector cũng rất giống như vậy. Một mạng neural có thể nén thông tin từ một câu không chỉ là một từ thành một vector có độ dài cố định. Thought vector là vector này, Chúng sử dụng một biểu diễn số của tài liệu để thúc đẩy một mô hình giải mã (Decoder),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một mạng seq2seq bao gồm 2 module mạng hồi quy với thought vector giữa chúng. Đầu ra của encoder là một thought vector ở cuối chuỗi đầu vào của nó. Decoder tiếp thu suy nghĩ (thought) đó và đứa ra một chuỗi tokens.\n",
    "\n",
    "Mạng đầu tiên gọi là encoder, turn văn bản đầu vào thành thought vector. Thought vector có 2 phần: đầu ra (kích hoạt) của lớp ẩn của bộ encoder và trạng thái bộ nhớ củaô LSTM cho ví dụ đầu vào đó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Encoder-decoder](./images/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thought vectorr trở thành đầu vào của mạng thứ 2: mạng decoder. Như bạn sẽ thấy trường phần sau, trạng thái đã được sinh sẽ như là trạng thái bắt đầu cả mạng decoder. Mạng thứ 2 sử dụng trạng thái khởi tạo đó và một input đặc biệt, gọi là *start token*. Với thông tin đó, mạng thứ 2 học để sinh các phần tử đầu tiên của chuỗi mục tiêu (các từ hoặc ký tự).\n",
    "\n",
    "Các giai đoạn đào tạo và suy luận được xử lý khác nhau trong thiết lập cụ thể này.Trong quá trình đào tạo, bạn chuyển văn bản bắt đầu đến bộ mã hóa và văn bản dự kiến là đầu vào cho bộ giải mã. Bạn đang nhờ mạng bộ giải mã tìm hiểu điều đó, với một trạng thái mồi và chìa khóa để “bắt đầu”, nó sẽ tạo ra một loạt các mã thông báo. Đầu tiên đầu vào trực tiếp cho bộ giải mã sẽ là mã thông báo bắt đầu; đầu vào thứ hai phải là đầu tiên mã thông báo dự kiến hoặc dự đoán, đến lượt nó sẽ nhắc mạng sản xuất mã thông báo dự kiến thứ hai.\n",
    "\n",
    "Tuy nhiên, tại thời điểm suy luận, bạn không có văn bản mong đợi, vì vậy bạn sử dụng để chuyển vào bộ giải mã khác với trạng thái? Bạn sử dụng mã thông báo bắt đầu chung và sau đó lấy phần tử được tạo đầu tiên, phần tử này sau đó sẽ trở thành đầu vào cho bộ giải mã tại bước thời gian tiếp theo, để tạo phần tử tiếp theo, v.v. Quá trình này lặp lại cho đến khi đạt đến số lượng phần tử trình tự tối đa hoặc mã dừng được tạo.\n",
    "\n",
    "Được đào tạo từ đầu đến cuối theo cách này, bộ giải mã sẽ biến một vectơ suy nghĩ thành một phản hồi đã giải mã cho chuỗi đầu vào ban đầu (chẳng hạn như câu hỏi của người dùng). Chia tách giải pháp thành hai mạng với vectơ suy nghĩ là mảnh ràng buộc ở giữa cho phép bạn ánh xạ các trình tự đầu vào thành các trình tự đầu ra có độ dài khác nhau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Unrolled encoder decoder](./images/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Look familar?\n",
    "## 1.3 Sequence-to-sequence conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 LSTM review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Next word predcition](./images/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Assembling a sequence-to-sequence pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Preparing your dataset for the sequence-to-sequence training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong trường hợp mạng tuần tự, bạn cũng cần chuẩn bị dữ liệu mục tiêu và\n",
    "nó để khớp với chuỗi mục tiêu dài nhất. Hãy nhớ rằng, độ dài trình tự của đầu vào và dữ liệu mục tiêu không cần giống nhau.\n",
    "![Input and target sequence before preprocessing](./images/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngoài các phần đệm bắt buộc (padding), chuỗi đầu ra nên chú thích với token start và token end, để cho bộ giải mã biết khi nào bắt đầu công việc và khi nào hoàn thành.\n",
    "![Input and target sequence after preprocessing](./images/5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn sẽ học làm thế nào để chú thích các chuỗi  mục tiêu trong chương sau khi bạn xây dựng pipeline Keras. Chỉ cần nhớ rằng bạn cần 2 phiên bản của chuỗi mục tiêu để training: một bắt đầu với start token (sử dụng làm đầu vào cho mạng decoder) và một không bắt đầu với start token (hàm lossfunction sẽ tính độ chính xác)\n",
    "\n",
    "Trong chương trước, tập huấn luyện của bạn bào cồn một cặp: đầu vào và một đầu ra. Mỗi mẫu training cho model seq2seq sẽ là bộ ba: input khởi tạo, ouput kỳ vọng (bắt đầu với start token), và output expected (không bắt đầu với start token).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Sequence-to-sequence model in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Sequence encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mục đích duy nhất của bộ mã hóa là tạo ra vector suy nghĩ, vector này sau đó dùng làm trạng thái ban đầu của bộ giải mã.\n",
    "![Thought vector](./images/6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab_size = 20000\n",
    "num_neurons = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encdder_inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3c295f418c82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoder_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencdder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mencoder_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encdder_inputs' is not defined"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, input_vocab_size))\n",
    "encoder = LSTM(num_neurons, return_state=True)\n",
    "encoder_output, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = (state_h, state_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![encoder](./images/7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Thought decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cũng giống như encoder, cài đặt mang decoder cũng khá dễ dàng và đơn giản. Sự khác biệt chính là lần này bạn muốn nắm bắt đầu ra của mạng tại mỗi time step. Bajn muốn đánh giá tính đúng đắng của đầu ra.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, output_vocab_size))\n",
    "decoder_lstm = LSTM(num_neurons, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
