{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nguồn tham khảo:\n",
    "- Fast R-CNN (Paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Abstract\n",
    "Paper này đề xuất một phương pháp Fast Region-based Convolutional Network (Fast R-CNN) cho object detection. Fast R-CNN xây dựng trên những nghiên cứu trước để phát hiện đối tượng một cách hiệu quả sử dụng mạng deep convolution. \n",
    "So với các nghiên cứu trước, Fast R-CNN có 1 số cải tiến để training hiệu quả và testing tốc độ đồng thời cũng tăng độ chính xác. Fast R-CNN train mạng rất sâu VGG16 và nhanh hơn 9 lần R-CNN, tốc độ test nhanh hơn 123 lần, và đạt một mAP cao trên PASCAL VOC 2012. so sánh với SPPnet, Fast R-CNN train VGG16 nhanh hơn 3 lần, test nhanh hơn 10 lần và độ chính xác cao hơn. Fast R-CNN thực thi trên python và C++ (Caffe) và có sẵn dưới dạng mã nguồn mở MIT license tại https://github.com/rbgirshick/fast-rcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Introduction\n",
    "Gần đây, deep ConvNets được cải thiện độ chính xác đáng kể trong bài toán phân lớp ảnh và phát hiện đối tượng. So với phân loại ảnh, phát hiện đối tượng là thách thức lớn hơn yêu cầu các phương pháp phức tạp hơn để giải quyết. Do sự phức tạp này, cách tiếp cận hiện nay train model ở nhiều giai đoạn là chậm.\n",
    "\n",
    "Phức tạp phát sinh vì phát hiện đối tượng yêu cầu chính xác vị trí các đối tượng, tạo 2 thách thức chính. Đầu tiên, nhiều đối tượng đề xuất phải xử lý. Thứ 2, các đối tượng đề xuất là thô và cần được tinh chỉnh để chính xác. Giải quyết các vấn đề này thường ảnh hưởng tốc độ, độ chính xác...\n",
    "\n",
    "Trong paper này, chúng tôi tinh giản quá trình training cho state-of-the-air ConvNet-based object detectors. Chúng tôi đưa ra một thuật toán training single-state mà cùng học cách đề xuất đối tượng và tinh chỉnh không gian đối tượng.\n",
    "\n",
    "Kết quả phương pháp có thể train một mạng deep detection (VGG16 nhanh hơn 9 lần R-CNN và 3 lần SPPnet). Tại mỗi lần chạy, mạng detection xử lý các hình ảnh trong 0.3s (bao gồm thời gian object proposal) trong khi độ chính xác trên PASCAL VOC 2012 với mAP đạt 66% (vs 62% cho R-CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 R-CNN and SPPnet\n",
    "R-CNN xuất sắc trong bài toán phát hiện đối tượng với độ chính xác cao sử dụng deep ConvNet để phân lớp các object proposal. Tuy nhiên, nó có 1 số nhược điểm đáng chú ý sau:\n",
    "1. **Training qua nhiều giai đoạn:** Đầu tiên R-CNN fine-tuning một ConvNet trên object proposal sử dụng log loss. Rồi nó fit SVM tới các đặc trưng ConvNet. Các SVM như là các trình phát hiện đối tượng, thay thế các class softmax đã học ở fine-tuning. Trong quá trình thứ 3, bouding-box regressor được học.\n",
    "2. **Training tốn kém không gian và thời gian:** Với quá trình training SVM và bouding-box regressor, các đặc trưng được trích xuất từ mỗi object proposal trong mỗi hình ảnh và lưu vào đĩa. Với mạng rất sâu, như VGG16, quá trình này cần 2.5 ngày GPT cho 5000 ảnh của tập trainval VOC07. Các đặc trưng yêu cầu hàng trăm GB lưu trữ.\n",
    "3. **Object detection là chậm:** Tại mỗi lần test, các đặc trưng được trích xuất từ mỗi object proposal trong mỗi ảnh test. Detection với BGG16 cần 47s/ ảnh (trên GPU)\n",
    "\n",
    "R-CNN là chậm bởi vì nó thực hiện một ConvNet qua mỗi object proposal, không chia sẻ tính toán.\n",
    "\n",
    "**BỐC PHÉT VỀ SPP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Contributions\n",
    "Chúng tôi đề xuất một thuật toán training mới sữa chữa nhược điểm của R-CNN và SPPnet , đồng thời cải thiện tốc độ và độ chính xác. Chúng tôi gọi phương pháp này là `Fast R-CNN` bởi vì nó nhanh hơn cho cả quá trình train và test. Phương pháp Fast R-CNN có 1 số ưu điểm:\n",
    "1. Chất lượng phát hiện (mAP) cao hơn R-CNN, SPPnet\n",
    "2. Training single-stage, sử dụng multi-task loss\n",
    "3. Training có thể cập nhật tất cả các layer mạng\n",
    "4. Không lưu trữ ra đĩa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fast R-CNN architecture and training\n",
    "**HÌNH 1** minh hoạ kiến trúc mạng Fast R-CNN. Một mạng Fast R-CNN lấy một input là một ảnh và một tập các object proposal. Mạng đầu tiên sẽ xử lý hình ảnh với conv và max pooling layer để cho ra một conv feature map. Rồi với mỗi object proposal một region of interest (RoI) pooling layer trích xuất 1 vector đặc trưng độ dài cố định. Mỗi vector đặc trưng được fed vào một chuỗi FC layer mà cuối cùng nhánh đi qua 2 sibling output lyaer: một lớp tạo ra các ước tính xác suất softmax trên các lớp đối tượng K cộng với một lớp nền nền bắt tất cả và một lớp khác tạo ra bốn số có giá trị thực cho mỗi lớp đối tượng K. Mỗi bộ 4 giá trị mã hóa các vị trí hộp giới hạn được tinh chỉnh cho một trong các lớp K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 The RoI pooling layer\n",
    "Layer RoI pooling sử dụng max pooling để chuyển các đặc trưng bên trong region of interest thành một bản đồ đặc trưng nhỏ (small feature map) với 1 phạm vi cố định HxW (ví dụ 7x7) với H và W là siêu tham só độc lập của bất kỳ RoI nào. Trong paper này, một Roi là một hình chữ nhật qua một conv feature map. Mỗi RoI được định nghĩa bởi bộ 4 số (r, c, h, w) tương ứng với toạ độ góc trên trái của nó (r,c) và chiều cao và chiều rộng (h,w).\n",
    "\n",
    "RoI max poolinbg làm việc bằng cách chia window hxw RoI thành các lưới sub-window HxW kích thước khoảng h/W x w/W và rồi max-pooling giá trị mỗi sub-window thành các cell lưới đầu ra tương ứng. Pooling áp dụng độc lập cho mỗi kênh feature map, như một max pooling chuẩn. Lớp ROI chỉ đơn giản là\n",
    "đặc biệt hợp cụ thể của kim tự tháp không gian lớp tổng hợp được sử dụng trong SPPnets trong đó chỉ có một mức kim tự tháp. Chúng tôi sử dụng pooling sub-window tổng hợp trong 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Initializing from pre-trained networks\n",
    "## 2.3 Fine-tuning for detection\n",
    "Training toàn weight của mạng với lan truyền ngược là quan trọng. First, let’s elucidate why SPPnet is unable to update weights below the spatial pyramid pooling layer.\n",
    "....\n",
    "Chúng tôi đề xuất một phương pháp huấn luyện hiệu quả ưu điểm ở việc chia sẻ đặc trưng trong quá trình hauasn luyện. Trong Fast R-CNN, SGD mini-batches lấy mẫu phân cấp, đầu tiên N mẫu hình ảnh và rồi R/N mẫu RóI từ mỗi ảnh. \n",
    "...\n",
    "**Multi-task loss:** Một mạng Fast R-CNN có 2 output layer. Output đầu tiên là phân phối (trên mỗi RoI), $p=(p_0, ..., p_K)$ trên K+1 thể loại. Thường $p$ được tính toán bởi hàm softmax trên K+1 đầu ra của lớp fully connected. Lớp output thứ 2 bouding-box regression dự đoán $t^k=(t_x^k, t_y^k, t_w^k, t_h^k)$, với mỗi lớp đối tượng K. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mỗi training RoI đã được gán nhãn với một lớp ground-truth $u$ và một ground-truth bouding box regression mục tiêu $v$. Chúng tôi sử dụng một hàm loss multi-task $L$ trên mỗi nhãn RoI để cả train cho phân lớp và bouding-box regression:\n",
    "$$L(p, u, t^u, v) = L_{cls}(p,u) + \\lambda[u \\ge 1] L_{loc}(t^u, v)$$\n",
    "trong đó $L_{cls}(p,u)=-log p_u$ là log loss cho class đúng u."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm loss thứ 2 là $L_{loc}$ định nghĩa qua một tupple bouding-box regression mục tiêu cho lớp u, $v=(v_x, v_y, v_w, v_h)$, và mọt tuple dự đoán $t^u=(t^u_x, t^u_y, t^u_w, t^u_h)$ cho class u. hàm $[g \\ge 1]$ bằng 1 khi $u \\ge 1$ và 0 trong các trường hợp còn lại, theo quy ước tất cả các lớp nền nhận nhãn $u=0$. Đối với Rois nền không có khái niệm về ground-truth bouding box và  và vì thế $L_{loc}$ là ignored. Với bouding box regression, chúng tôi sử dụng loss:\n",
    "$$L_{loc}(t^u, v) = \\sum_{i \\in \\{x,y,w,h\\}} smooth_{L1} (t^u_i - v_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trong đó:\n",
    "$smooth_{L1}(x)=0.5x^2$ nếu $|x| <1$ và bằng $|x|-0.5$ các trường hợp khác."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "là một L1 mất mạnh mẽ đó là ít nhạy cảm với giá trị ngoại biên hơn\n",
    "mất L2 sử dụng trong R-CNN và SPPnet. Các siêu tham số λ trong phương trình. 1 điều khiển sự cân bằng giữa hai lỗ nhiệm vụ. (các thí nghiệm cài là 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Fast R-CNN detection\n",
    "\n",
    "# 4. Main result\n",
    "\n",
    "# 5. Design evaluation\n",
    "\n",
    "# 6. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
