{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nguồn:\n",
    "1. Mask R-CNN (Paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Abstract\n",
    "Chúng tôi trình bày một khái niệm đơn giản, linh hoạt, và khung chung cho object instance segmentation. Cách tiếp cận của chúng tôi phát hiện một cách hiệu quả các đối tượng là một hình ảnh trong khi đồng thời sinh một mặt nạ chất lượng cao cho mỗi instance. Phương pháp gọi là Mask R-CNN, mở rộng của Faster R-CNN bằng cách thêm một nhánh dự đoán mặt nạ đối tượng song song với nhánh bounding box recognition đã tồn tại. Mask R-CNN đơn giản đế huấn luyện và chỉ thêm một chi phí nhỏ vào Faster R-CNN, chạy 5fps. Tuy nhiên, Mask R-CNN đơn giản để khái quát các nhiệm vụ khác, ví dụ cho phép ước lượng tư thế của con người trong cùng một khuôn khổ. Chúng tôi cho thấy top kết quả trong cả 3 track của COCO, bao gồm instance segmentation, bounding box object detection, và person keypoint detection. Mask R-CNN nhanh hơn so với tất cả các mô hình hiện có, mô hình đơn giản trên tất cả các nhiệm vụ, thắng thử thách COCO 2016. Chúng tôi hy vọng sự đơn giản của chúng và cách tiếp cận hiệu quả sẽ đóng vai trò như một cơ sở vững chắc và giúp nghiêm cứu trong tương lai về instance-level regonition. Code có thể xem tại: https://github.com/facebookresearch/Detectron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "cộng đồng vision đã nhanh chóng cải tiến hiệu suất của phát hiện đối tượng (object detect) và sematic segmentation trong một thời gian ngắn. Phần lớn, các hệ thống tiến bộ được thúc đẩy bởi hệ thống mạnh mẽ như Fast/Faster R-CNN và FCN cho object dectection và sematic segmentation. Các phương pháp này là khái niệm trực quan và cung cấp linh hoạt mạnh mẽ, đào tạo nhanh và suy luận nhanh. Mục tiêu của chúng tôi trong công việc này là phát triển một khung cho *instance segmentation*.\n",
    "\n",
    "*Instance segmetation* là thách thức bởi vì nó yêu cầu phát hiện chính xác tất cả đối tượng trong một hìh ảnh đồng thời cũng phân đoạn mỗi đối tượng. Do đó tổ hợp các phần tử từ bài toán phân lớp computer vision cho object detect, tại đây mục tiêu là phân lớp object riêng và localize sử dụng bounding box, và sematic segmentaion, tại đây mục tiêu là phân lớp mỗi pixel trong tập cố định các danh mục không phân biệt đối tượng instances. Với này, người ta kỳ vọng một phương pháp phức tạp để cho kết quả tốt. Tuy nhiên, chúng tôi chỉ ra một hệ thống đáng ngạc nhiên, đơn giản và linh hoạt và nhanh có thể vượt qua các kết quả kiến trúc instance segmentation.\n",
    "\n",
    "Phương pháp của chúng tôi gọi là *Mask R-CNN*, mở rộng của Faster R-CNN bằng cách thêm một nhánh dự đoán segmentaion maskss trên mỗi Region of Interest (RoI), và song song với nhánh phân lớp và bounding box regression đã tồn tại (Hình 1). Nhánh mặt nạ là một FCN nhỏ áp dụng cho mỗi RoI, dự đoán một mặt nạ segmentation trong một pixel-to-pixel. Mask R-CNN đơn giản để triển kahi và train cho khung Faster R-CNN, tạo một điều kiện một loạt các thiết kế linh hoạt. Thêm nữa, nhánh mặt nạ chỉ thêm một computational overhead, tạo điều kiện cho một hệ thống nhanh chóng và thử nghiệm nanh chóng.\n",
    "\n",
    "Trong Mask R-CNN nguyên tắc là một phần mở rộng của Faster R-CNN, chưa xây dựng nhánh mặt nạ đúng là rất quan trọng cho kết quả một. Quan trọng nhất, Faster R-CNN không được thiết kế pixel-to-pixel liên kết giữa mạng input và output. Đây là điều hiển nhiên nhất trong cách RoIPool [18, 12], trên thực tế hoạt động cốt lõi cho tham dự vào các trường hợp, thực hiện thô lượng tử hóa không gian cho khai thác tính năng. Để khắc phục những lệch chi tiết, chúng tôi đề xuất một đơn giản, lớp lượng tử miễn phí, gọi RoIAlign, mà trung thành bảo tồn các địa điểm không gian chính xác. Mặc dù là một sự thay đổi dường như nhỏ, RoIAlign có tác động lớn: nó cải thiện độ chính xác mặt nạ bằng cách tương đối 10% đến 50%, cho thấy lợi nhuận lớn hơn dưới số liệu nội địa hóa chặt chẽ hơn. Thứ hai, chúng tôi tìm thấy nó cần thiết để mặt nạ tách và dự đoán lớp: chúng tôi\n",
    "dự đoán một mặt nạ nhị phân cho mỗi lớp một cách độc lập, mà không cạnh tranh giữa các lớp, dựa vào RoI của mạng để dự đoán category. Ngược lại, FCNs thường thực hiện mỗi điểm ảnh đa lớp phân loại, which couples segmentation and classification, and based on our experiments works poorly for instance segmentation.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Related work\n",
    "**R-CNN:** ...\n",
    "\n",
    "**Instance segmentation:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Mask R-CNN\n",
    "Mask R-CNN là khái niệm đơn giản: Faster R-CNN có 2 output cho mỗi đối tượng đề xuất, một class label và một bouding box offset; này chúng ta thêm một chi nhánh thứ ba mà kết quả đầu ra mặt nạ đối tượng. Mask R-CNN là một ý tưởng tự nhiên và trực quan. Nhưng thêm mặt nạ đầu ra là phân biệt với đầu ra class và box, yêu cầu trích xuất nhiều *finer* bố trí không gian của một đối tượng. Tiếp theo, chúng tôi giới liệu các phần tử khoá của Mask R-CNN, bao gồm pixel-to-pixel alignment, cái mà còn thiếu của Fast/Faster R-CNN.\n",
    "\n",
    "**Faster R-CNN:** Chúng tôi bắt đầu bằng cách tóm tắt về Faster R-CNN. Faster R-CNN bao gồm 2 giai đoạn. Giai đoạn đầu tiên, được gọi là RPN, đề xuất các hộp cho đối tượng. Giai đoạn thứ 2, bản chất là Fast R-CNN, trích xuất đặc trưng sử dụng RoIPool từ mỗi box đề xuất và phân lớp hiệu quả và bounding-box regression. Các đặc trừng được sử dụng bởi các trạng thái có thể chia sẻ cho nhanh. Chúng tôi tham khảo thêm [21] để so sánh Faster R-CNN và các framework khác.\n",
    "\n",
    "**Mask R-CNN:** Mask R-CNN thông qua 2 giai đoạn, với trạng thái đầu tiên giống hệt (RPN). Trong trạng thái thứ 2, song song dự đoán clas và box offset, Mask R-CNN cũng xuất ra mặt nạ nhị phân cho mỗi RoI. Điều này là trái ngược với hầu hết các hệ thống gần đây, khi mà phân loại phụ thuộc vào mặt nạ ([33, 10, 26]).  Cách tiếp cận của chúng tôi theo tinh thần của Faster R-CNN áp dụng  bounding box regression classification và regression trong song song.\n",
    "\n",
    "Một cách chính thức, trong đào tạo, chúng tôi định nghĩa một loss đa tác vụ trên mỗi mẫu RoI là $L=L_{cls}+L_{box}+L_{mask}$. Classification lass $L_{cls}$ và bounding-box loss $L_{box}$ là giống hệt như những gì định nghĩa ở [12]. Nhánh mặt nạ có $K m^2$ chiều output cho mỗi RoI, mã hoá $K$ mặt nạ nhị phân độ phân giải $mxm$. Và điều này chúng tôi áp dụng sigmoid cho mỗi pixel, và định nghĩa $L_{mask}$ chỉ được định nhigã trên mặt nạ thứ $k$ (kết quả đầu ra mặt nạ khác không đóng góp vào sự mất mát).\n",
    "\n",
    "Định nghĩa $L_{mask}$ của chúng tôi cho pháp mạng sinh các mặt nạ cho mỗi class không cần competition giữa các lớp, chúng tôi dựa vào các nhánh phân loại class để dựa đoán class label được sử dụng để chọn mặt nạ đầu ra. Tách riêng mặt là class dự đoán. Đều này khác với khi áp dụng FCNs [30] để sematic segmentation, cái mà thường sử dụng softmax trên mỗi pixel và mutinomial cross-entropy loss. Trong trường hợp khác, các mặt nạ trên các lớp cạnh tranh; trong trường hợp của chúng tôi, với sigmoid trên mỗi pixel và binary loss, chúng không thế. chúng tôi chỉ ra rằng bằng thực nghiệm xây dựng này là chìa khoá tốt cho kết quả instance segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mask Representation:** Một mặt nã mã hoá một đối tượng đầu vào. Vì vậy, không giống như nhãn lớp hoặc offsets hộp được chắc chắn sụp đổ vào vectơ đầu ra ngắn bởi đầy đủ kết nối (fc) lớp, trích xuất cấu trúc không gian của các mặt nạ có thể  giải quyết tự nhiên bằng các pixel-to-pixel tương ứng được cung cấp bởi nhiều convolution.\n",
    "\n",
    "Đặc biệt, chúng tôi dự đoán một mặt nạ $m \\times m$ từ mỗi RoI sử dụng FCN [30]. Điều này chó phép mỗi layer trong nhánh mặt nạ duy trì rõ ràng đối tượng $m \\times m$ layout không gian mà không bị sụp đổ nó vào một biểu diễn vectơ thiếu chiều không gian. Không giống như các phương pháp trước đó để resort layer *fc* cho dự đoán mặt nạ [33, 34, 10], biểu diễn convolution đầy đủ của chúng tôi yêu cầu tham số ít hơn và chính xác hơn bằng thực nghiệm.\n",
    "\n",
    "pixel-to-pixel đòi hỏi các đặc trưng RoI, cái mà chính chúng là một bản đồ đặc trưng nhỏ, được liên kết tốt để trung thành giữ gìn mỗi pixel thư từ không gian rõ ràng.Đây thúc đẩy chúng tôi để phát triển những điều sau đây RoIAlign lớp mà đóng một vai trò quan trọng trong mặt nạ dự đoán."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RoIAlign:** RoIPool [12] là một toán tử chuẩn để trích xuất các feature map nhỏ (ví dụ 7x7) từ mỗi RoI. RoIPool trước tiên định lượng RoI số trôi nổi đến độ chi tiết rời rạc của bản đồ tính năng, RoI được lượng tử hóa này sau đó được chia thành các thùng không gian tự lượng tử hóa và cuối cùng các giá trị tính năng được bao phủ bởi mỗi thùng được tổng hợp (thường bằng cách gộp tối đa). Lượng tử hoá được thực hiện, ví dụ một toạ độ x liên tục bằng các tính [x/16]; tại đây 16 là một bước xải bản đồ đặc trừng và [] là àm tròn;  tương tự như vậy, lượng tử hóa được thực hiện khi chia vào thùng. Những lượng hóa này đưa ra sự sai lệch giữa RoI và các tính năng được trích xuất. Trong khi điều này có thể không ảnh hưởng phân loại, mạnh mẽ cho các bản dịch nhỏ, nó có một ảnh hưởng tiêu cực lớn đến dự đoán mặt nạ chính xác pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để giải quyết vấn đề này, chúng tôi đề xuất *RoiAlign* loại bỏ các lượng tử hoá khắc nghiệt của RoIPool, sắp xếp đúng cách các tính năng trích xuất đầu vào. Đề xuất của chúng tôi thay đổi đơn giản: chúng tôi tránh bất kỳ lượng tử hoá của ranh giới RoI hoặc bins (ví dụ chúng ta sử dụng x/16 thay vì [x/16]). Chúng tôi sử dụng nội suy bilinear để tính toán chính xác các giá trị của đặc trưng đầu vào cho 4 địa điểm thường xuyên lấy mỗi trong RoI bin, và tổng hợp kết quả (sử dụng max or average), xem hình 3. Chúng tôi nhớ rằng kết quả là không nhạt cảm đến các địa điểm lấy mẫu chính xác, hoặc nhiều điểm là mẫu ntn, miễn là không lượng tử hoá."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoIAlign dẫn đến những cải tiến lớn như chúng ta thấy trong\n",
    "x4.2. Chúng tôi cũng so sánh với các hoạt động đề xuất RoIWarp\n",
    "trong [10]. Không giống như RoIAlign, RoIWarp bỏ qua các vấn đề liên kết và đã được thực hiện tại [10] như quantizing ROI\n",
    "giống như RoIPool. Vì vậy, mặc dù RoIWarp cũng thông qua\n",
    "Bilinear resampling thúc đẩy bởi [22], nó thực hiện trên mệnh\n",
    "với RoIPool như thể hiện bởi thí nghiệm (chi tiết trong Bảng 2c), thể hiện vai trò quan trọng của liên kết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
