{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier cho bài toán spam filtering (phân loại thư rác)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mô tả dữ liệu Tập dữ liệu này gồm 960 email tiếng Anh, được tách thành traning set và test set theo tỉ lệ 700:260 với 50% trong mỗi tập là các spam email.\n",
    "\n",
    "Dữ liệu trong cơ sở dữ liệu này đã được xử lý. Các quy tắc xử lý:\n",
    "\n",
    "1. Loại bỏ stop words: loại bỏ những từ không cần thiết, không ảnh hưởng nhiều đến việc quyết định\n",
    "2. Lemmatization: đưa những từ gốc về cùng loại.\n",
    "3. Loại bỏ non-words: loại bỏ các chữ số, kí tự, dấu câu.\n",
    "\n",
    "Danh sách các file txt:\n",
    "\n",
    "train-features-50.txt: chứa dữ liệu của tranning set thu gọn với 50 email.\n",
    "\n",
    "labels.txt: chứa nhiều dòng, mỗi dòng là một kí tự 0 hoặc 1 thể hiện email non-spam hoặc spam.\n",
    "\n",
    "features.txt: chứa nhiều dòng, mỗi dòng gồm 3 số:\n",
    "\n",
    "Vd: 1 564 1, 1 19 2.\n",
    "\n",
    "Trong đó số đầu tiên là chỉ số của email, số thứ hai là thứ tự của từ trong từ điển, số thứ ba là số lượng từ đó trong email đang xét. 1 564 1 , email 1, từ thứ 564, xuất hiện trong từ điển 1 lần. Nếu biểu diễn mỗi email bằng một vector hàng có độ dài từ điển 2500 thì dòng thứ nhất nói rằng đặc trưng thứ 564 của vector này bằng 1, tương tự đặc trưng thứ 19 của vector này bằng 2.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix # for sparse matrix\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score # for evaluating results\n",
    "\n",
    "# data path and file name \n",
    "path = 'ex6DataPrepared/'\n",
    "train_data_fn = 'train-features.txt'\n",
    "test_data_fn = 'test-features.txt'\n",
    "train_label_fn = 'train-labels.txt'\n",
    "test_label_fn = 'test-labels.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem dữ liệu\n",
    "\n",
    "\n",
    "Label của dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "with open(path + train_label_fn) as f:\n",
    "    content = f.readlines()\n",
    "    label = [int(x.strip()) for x in content]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features của dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(path + train_data_fn) as f:\n",
    "    content = f.readlines()\n",
    "    #print(\"Dữ liệu đọc được:\",content)\n",
    "    # remove '\\n' at the end of each line\n",
    "    content = [x.strip() for x in content] \n",
    "    #print(\"\\nDữ liệu:\\n\")\n",
    "    #print(content)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đưa dữ liệu features về chuẩn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1   19    2]\n",
      " [   1   45    1]\n",
      " [   1   50    1]\n",
      " ...\n",
      " [ 700 2479    2]\n",
      " [ 700 2481    2]\n",
      " [ 700 2500    3]]\n"
     ]
    }
   ],
   "source": [
    "dat = np.zeros((len(content), 3), dtype = int)\n",
    "for i, line in enumerate(content): \n",
    "        a = line.split(' ')\n",
    "        dat[i, :] = np.array([int(a[0]), int(a[1]), int(a[2])])\n",
    "print(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đưa dữ liệu về coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 18)\t2\n",
      "  (0, 44)\t1\n",
      "  (0, 49)\t1\n",
      "  (0, 74)\t1\n",
      "  (0, 84)\t1\n",
      "  (0, 138)\t1\n",
      "  (0, 199)\t1\n",
      "  (0, 350)\t1\n",
      "  (0, 351)\t1\n",
      "  (0, 512)\t1\n",
      "  (0, 563)\t1\n",
      "  (0, 742)\t1\n",
      "  (0, 776)\t1\n",
      "  (0, 1130)\t1\n",
      "  (0, 1276)\t1\n",
      "  (0, 1638)\t1\n",
      "  (0, 1763)\t1\n",
      "  (0, 1815)\t1\n",
      "  (0, 1867)\t1\n",
      "  (1, 34)\t5\n",
      "  (1, 96)\t1\n",
      "  (1, 102)\t2\n",
      "  (1, 158)\t1\n",
      "  (1, 293)\t2\n",
      "  (1, 726)\t1\n",
      "  :\t:\n",
      "  (699, 2048)\t4\n",
      "  (699, 2054)\t4\n",
      "  (699, 2057)\t2\n",
      "  (699, 2071)\t4\n",
      "  (699, 2084)\t2\n",
      "  (699, 2108)\t3\n",
      "  (699, 2126)\t1\n",
      "  (699, 2172)\t1\n",
      "  (699, 2198)\t3\n",
      "  (699, 2226)\t1\n",
      "  (699, 2231)\t1\n",
      "  (699, 2236)\t1\n",
      "  (699, 2244)\t1\n",
      "  (699, 2325)\t1\n",
      "  (699, 2356)\t3\n",
      "  (699, 2377)\t2\n",
      "  (699, 2397)\t4\n",
      "  (699, 2401)\t1\n",
      "  (699, 2418)\t1\n",
      "  (699, 2432)\t1\n",
      "  (699, 2433)\t1\n",
      "  (699, 2471)\t1\n",
      "  (699, 2478)\t2\n",
      "  (699, 2480)\t2\n",
      "  (699, 2499)\t3\n"
     ]
    }
   ],
   "source": [
    "data = coo_matrix((dat[:, 2], (dat[:, 0] - 1, dat[:, 1] - 1)),shape=(len(label), nwords))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwords = 2500 \n",
    "\n",
    "def read_data(data_fn, label_fn):\n",
    "    ## read label_fn\n",
    "    with open(path + label_fn) as f:\n",
    "        content = f.readlines()\n",
    "    label = [int(x.strip()) for x in content]\n",
    "\n",
    "    ## read data_fn\n",
    "    with open(path + data_fn) as f:\n",
    "        content = f.readlines()\n",
    "    # remove '\\n' at the end of each line\n",
    "    content = [x.strip() for x in content] \n",
    "\n",
    "    dat = np.zeros((len(content), 3), dtype = int)\n",
    "    \n",
    "    for i, line in enumerate(content): \n",
    "        a = line.split(' ')\n",
    "        dat[i, :] = np.array([int(a[0]), int(a[1]), int(a[2])])\n",
    "    \n",
    "    # remember to -1 at coordinate since we're in Python\n",
    "    # check this: https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html\n",
    "    # for more information about coo_matrix function \n",
    "    data = coo_matrix((dat[:, 2], (dat[:, 0] - 1, dat[:, 1] - 1)),\\\n",
    "             shape=(len(label), nwords))\n",
    "    return (data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 18)\t2\n",
      "  (0, 44)\t1\n",
      "  (0, 49)\t1\n",
      "  (0, 74)\t1\n",
      "  (0, 84)\t1\n",
      "  (0, 138)\t1\n",
      "  (0, 199)\t1\n",
      "  (0, 350)\t1\n",
      "  (0, 351)\t1\n",
      "  (0, 512)\t1\n",
      "  (0, 563)\t1\n",
      "  (0, 742)\t1\n",
      "  (0, 776)\t1\n",
      "  (0, 1130)\t1\n",
      "  (0, 1276)\t1\n",
      "  (0, 1638)\t1\n",
      "  (0, 1763)\t1\n",
      "  (0, 1815)\t1\n",
      "  (0, 1867)\t1\n",
      "  (1, 34)\t5\n",
      "  (1, 96)\t1\n",
      "  (1, 102)\t2\n",
      "  (1, 158)\t1\n",
      "  (1, 293)\t2\n",
      "  (1, 726)\t1\n",
      "  :\t:\n",
      "  (699, 2048)\t4\n",
      "  (699, 2054)\t4\n",
      "  (699, 2057)\t2\n",
      "  (699, 2071)\t4\n",
      "  (699, 2084)\t2\n",
      "  (699, 2108)\t3\n",
      "  (699, 2126)\t1\n",
      "  (699, 2172)\t1\n",
      "  (699, 2198)\t3\n",
      "  (699, 2226)\t1\n",
      "  (699, 2231)\t1\n",
      "  (699, 2236)\t1\n",
      "  (699, 2244)\t1\n",
      "  (699, 2325)\t1\n",
      "  (699, 2356)\t3\n",
      "  (699, 2377)\t2\n",
      "  (699, 2397)\t4\n",
      "  (699, 2401)\t1\n",
      "  (699, 2418)\t1\n",
      "  (699, 2432)\t1\n",
      "  (699, 2433)\t1\n",
      "  (699, 2471)\t1\n",
      "  (699, 2478)\t2\n",
      "  (699, 2480)\t2\n",
      "  (699, 2499)\t3\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Training size = 700, accuracy = 98.08%\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_label)  = read_data(train_data_fn, train_label_fn)\n",
    "(test_data, test_label)  = read_data(test_data_fn, test_label_fn)\n",
    "print(train_data)\n",
    "print(train_label)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_data, train_label)\n",
    "\n",
    "y_pred = clf.predict(test_data)\n",
    "print('Training size = %d, accuracy = %.2f%%' % \\\n",
    "      (train_data.shape[0],accuracy_score(test_label, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng mô hình Multinomial navie Bayes cho dữ liệu training nhỏ hơn 100 email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size = 100, accuracy = 97.69%\n",
      "Training size = 50, accuracy = 97.31%\n"
     ]
    }
   ],
   "source": [
    "train_data_fn = 'train-features-100.txt'\n",
    "train_label_fn = 'train-labels-100.txt'\n",
    "test_data_fn = 'test-features.txt'\n",
    "test_label_fn = 'test-labels.txt'\n",
    "\n",
    "(train_data, train_label)  = read_data(train_data_fn, train_label_fn)\n",
    "(test_data, test_label)  = read_data(test_data_fn, test_label_fn)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_data, train_label)\n",
    "y_pred = clf.predict(test_data)\n",
    "print('Training size = %d, accuracy = %.2f%%' % \\\n",
    "      (train_data.shape[0],accuracy_score(test_label, y_pred)*100))\n",
    "\n",
    "train_data_fn = 'train-features-50.txt'\n",
    "train_label_fn = 'train-labels-50.txt'\n",
    "test_data_fn = 'test-features.txt'\n",
    "test_label_fn = 'test-labels.txt'\n",
    "\n",
    "(train_data, train_label)  = read_data(train_data_fn, train_label_fn)\n",
    "(test_data, test_label)  = read_data(test_data_fn, test_label_fn)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_data, train_label)\n",
    "y_pred = clf.predict(test_data)\n",
    "print('Training size = %d, accuracy = %.2f%%' % \\\n",
    "      (train_data.shape[0],accuracy_score(test_label, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng mô hình Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size = 50, accuracy = 69.62%\n"
     ]
    }
   ],
   "source": [
    "clf = BernoulliNB(binarize = .5)\n",
    "clf.fit(train_data, train_label)\n",
    "y_pred = clf.predict(test_data)\n",
    "print('Training size = %d, accuracy = %.2f%%' % \\\n",
    "      (train_data.shape[0],accuracy_score(test_label, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
