{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nguồn\n",
    "1. https://phamdinhkhanh.github.io/2019/08/10/PytorchTurtorial1.html#21-autograd-t%E1%BB%B1-%C4%91%E1%BB%99ng-t%C3%ADnh-%C4%91%E1%BA%A1o-h%C3%A0m\n",
    "2.https://minhng.info/ai/pytorch-co-ban.html\n",
    "\n",
    "# Nội dung kiến thức\n",
    "1. Giới thiệu về Pytorch\n",
    "2. Tensor\n",
    "3. Các toán tử trên Tensor\n",
    "4. Broadcast\n",
    "5. Variable <br/>\n",
    "    5.1 Khởi tạo Variable <br/>\n",
    "    5.2 Autograd <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Giới thiệu về Pytorch\n",
    "\n",
    "Chào mọi người, đây là bài viết đầu tiên của năm 2021 và cũng là bài trở lại sau nửa năm bận rộn và tẩu hỏa của mình :D. Mình trở lại để viết tiếp những chuỗi bài về AI để chia sẻ kiến thức cũng như tự củng cố cho bản thân. Và hôm nay chúng ta tìm hiểu về Pytorch.\n",
    "\n",
    "Pytorch là 1 framework được xây dựng trên python cung cấp nền tảng tính toán trong lĩnh vực Deep learning, cùng với Tensorflow, Pytorch đang là framework được cộng đồng Deep learning ưa chuộng nhất hiện nay.\n",
    "\n",
    "Tensorflow thì được ưa chuộng để build lên các sản phẩm thực tế, deploy mô hình, áp dụng vào các hệ thống lớn. Còn Pytorch thì có vẻ được ưa chuộng trong nghiên cứu. Về cá nhân mình khi tìm hiểu cả 2 thì mình có hứng thú với pytorch hơn vì cảm thấy tính rõ ràng trong nó. Phong cách code pytorch tương đồng python. Và nó sở hữu khả năng tính toán GPU mạnh mẽ, mang lại hiệu năng tính toán cao."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ chúng ta hãy cùng xem xét pipeline cơ bản của một dự án Pytorch. Hình dưới đây mô tả một quy trình công việc điển hình cùng các modules quan trọng được liên kết ở mỗi bước.\n",
    "![1](./images/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có thể thấy các modules cơ bản của pytorch như là: **torch.utils.data, torch.nn, torch.optim, torch.utils, torch.autograd...**\n",
    "\n",
    "Chúng ta sẽ cùng tìm hiểu chi tiết thông qua các ví dụ ở các bài sau.\n",
    "\n",
    "Về hướng dẫn cài đặt, các bạn có thể xem trên trang chủ của pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tensor\n",
    "Tensor là kiểu dữ liệu chính trong Pytorch, có thể hình dung Tensor là khối ma trận nhiều chiều. Việc khởi tạo và truy xuất tương tự numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.3005e-29,  1.2083e-38,  1.1590e-26,  2.3036e-39],\n",
      "        [-4.2990e-35,  1.2171e-38,  6.4620e+16, -2.8977e-27],\n",
      "        [ 4.8123e-38, -2.7642e-27,  1.6132e+16, -4.7328e-26]])\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo tensor ngẫu nhiên có kích thước 3 hàng 4 cột\n",
    "import torch\n",
    "x = torch.Tensor(3,4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0515, 0.2511, 0.0280, 0.4123],\n",
      "        [0.5357, 0.6541, 0.4171, 0.1434],\n",
      "        [0.9501, 0.2531, 0.2801, 0.4306]])\n"
     ]
    }
   ],
   "source": [
    "# khởi tạo tensor phân phối đều\n",
    "x = torch.rand(3,4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 5.],\n",
      "        [4., 3.],\n",
      "        [1., 5.]])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo tensor nhiều chiều\n",
    "x = torch.Tensor([[2,5], [4,3], [1,5]])\n",
    "print(x)\n",
    "print(x.size()) # Kiểm tra kích cỡ Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# khởi tạo ma trận 0 với data type là long\n",
    "x = torch.zeros(3, 4, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "tensor([1, 2, 3])\n",
      "[2 3 4]\n",
      "tensor([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo từ kiểu dữ liệu numpy\n",
    "import numpy as np\n",
    "x = np.array([1,2,3])\n",
    "y = torch.from_numpy(x)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print(y)\n",
    "\n",
    "y += 1\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi chuyển đổi x thành Tensor y. Mà tensor y cộng thêm 1 đơn vị thì x cũng tự động thay đổi theo. Chúng ta cũng có thể chuyển đổi ngược tensor về numpy như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Chuyển đổi tensor sang numpy\n",
    "z = y.numpy()\n",
    "print(z)\n",
    "print(type(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có nhiều cách khởi tạo nữa, khá giống với Tensorflow và numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tính toán trên GPU nhanh gấp nhiều lần CPU. Tensor hỗ trợ việc tính toán trên GPU, mặc định Tensor tạo theo cách thông thường sẽ nằm trên CPU. Để đem Tensor lên GPU tính toán, chúng ta dùng phương thức  **.cuda()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1,2,3])\n",
    "y = torch.Tensor([4,5,6])\n",
    "if torch.cuda.is_available(): # kiểm tra xem máy tính hỗ trợ CUDA ko\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    print(x + y)\n",
    "else:\n",
    "    print('Cuda is not available!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem thêm: https://pytorch.org/docs/0.3.0/tensors.html#torch-tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Các toán tử trên Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Resize: *view()*\n",
    "* Phép cộng: *torch.add(a,b) = a + b*\n",
    "* Phép trừ: *a.sub(b) = a - b*\n",
    "* Phép nhân tương ứng từng phần tử: *torch.mul(a,b) = a * b*\n",
    "* Phép chia tương ứng từng phần tử: *torch.div(a,b) = a / b*\n",
    "* Mean: *a.mean()*\n",
    "* Độ lệch tiêu chuẩn (std): *a.std()*\n",
    "* Chuyển tensor 1 phần tử sang numeric python: *item()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6835,  0.0084,  0.3737],\n",
      "        [ 0.1589,  0.7473,  0.4028],\n",
      "        [-0.5508,  0.2677,  0.5509]])\n",
      "tensor([[ 1.9175, -0.6483, -0.6887],\n",
      "        [-0.4578,  0.0642,  0.8489],\n",
      "        [-1.4211,  0.6726, -0.7297]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,3)\n",
    "print(x)\n",
    "\n",
    "y = torch.randn(3,3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x+y: tensor([[ 3.6010, -0.6399, -0.3150],\n",
      "        [-0.2989,  0.8116,  1.2517],\n",
      "        [-1.9719,  0.9404, -0.1789]])\n",
      "x-y: tensor([[-0.2341,  0.6566,  1.0624],\n",
      "        [ 0.6167,  0.6831, -0.4461],\n",
      "        [ 0.8703, -0.4049,  1.2806]])\n",
      "x*y: tensor([[ 3.2281, -0.0054, -0.2574],\n",
      "        [-0.0728,  0.0480,  0.3419],\n",
      "        [ 0.7827,  0.1801, -0.4020]])\n",
      "x/y: tensor([[ 0.8779, -0.0129, -0.5427],\n",
      "        [-0.3471, 11.6326,  0.4745],\n",
      "        [ 0.3876,  0.3980, -0.7549]])\n",
      "mean of x: tensor(0.4047)\n",
      "std of y: tensor(1.0301)\n"
     ]
    }
   ],
   "source": [
    "print(\"x+y:\", x+y)\n",
    "print(\"x-y:\", x-y)\n",
    "print(\"x*y:\", x*y)\n",
    "print(\"x/y:\", x/y)\n",
    "print(\"mean of x:\", x.mean())\n",
    "print(\"std of y:\", y.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.6835,  0.0084,  0.3737,  0.1589,  0.7473,  0.4028, -0.5508,  0.2677,\n",
      "         0.5509])\n",
      "torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# reshape x\n",
    "z = x.view(9)\n",
    "print(z)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Chuyển tensor 1 phaafnf tử sang numeric python\n",
    "x = torch.tensor([1.5])\n",
    "i = x.item()\n",
    "print(i, type(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Broadcast\n",
    "Broadcast cho phép ta thực hiện các toán tử giữa 2 tensor của pytorch/mảng numpy không cùng số chiều. Quy tắc Broadcast như sau:\n",
    "* Thêm chiều vào phía trước tensor có chiều ngắn hơn cho đến khi 2 tensor bằng nhau.\n",
    "* Số phần tử của mỗi chiều của 2 tensor phải:\n",
    "    - bằng nhau, hoặc\n",
    "    - một tensor có một phần tử, giá trị của phần tử được nhân bản thành k phần tử (bằng số phần tử của tensor còn lại ở chiều đang xét)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4644, 0.0326, 0.3631]],\n",
      "\n",
      "        [[0.5650, 0.8192, 0.5750]]])\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([[[1.4644, 1.0326, 1.3631],\n",
      "         [1.4644, 1.0326, 1.3631],\n",
      "         [1.4644, 1.0326, 1.3631]],\n",
      "\n",
      "        [[1.5650, 1.8192, 1.5750],\n",
      "         [1.5650, 1.8192, 1.5750],\n",
      "         [1.5650, 1.8192, 1.5750]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,1,3)\n",
    "y = torch.ones(3,1)\n",
    "print(x)\n",
    "print(y)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giải thích:\n",
    "* Kích thước của x: 2x1x3\n",
    "* Kích thước của y: 3x1\n",
    "* Broadcast:\n",
    "    - Thêm chiều vào phía trước của y cho đến khi số chiều bằng x --> y là 1x3x1\n",
    "    - Xét chiều thứ 0: Chiều 0 của y là 1, nhỏ hơn x (là 2) --> kích thước y: 2x3x1\n",
    "    - Xét chiều thứ 1: Chiều 1 của y là 3, lớn hơn x (là 1) --> Kích thước x: 2x3x3\n",
    "    - Xét chiều thứ 2: Chiều 2 của y là 1, nhỏ hơn x (là 3) --> Kích thước y: 2x3x3\n",
    "* Kết quả kích thước tensor đầu ra: 2x3x3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu vi phạm quy tắc broadcast sẽ báo lỗi.\n",
    "\n",
    "(Khi thêm chiều y: 1x3x1x1, x là: 5x2x4x1 --> Vi phạm ở chiều 1 của x và y - không bằng nhau số chiều mà 1 trong 2 cũng không phải là tensor 1 phần tử ở chiều 1 đó)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b4fcf6bd94b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "x=torch.FloatTensor(5,2,4,1)\n",
    "y=torch.FloatTensor(3,1,1)\n",
    "(x+y).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable là class bao bọc (wrapper) Tensor cho phép thực hiện tính toán đạo hàm. Variable lưu trữ **data** (tensor) và **grad** (gradient)\n",
    "![img](./images/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Khởi tạo Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "x = Variable(torch.ones(2,2), requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mỗi một tensor torch sẽ có 1 thuộc tính là **.requires_grad**, nếu bạn set thuộc tính này về True, các toán tử triển khai trên tensor sẽ được theo dõi. Khi kết thúc quá trình lan truyền thuận (hoặc quá trình tính toán output) bạn có thể gọi **.backward()** và mọi tính toán gradient sẽ được tự động thực hiện dựa trên lịch sử đã được lưu lại. Các gradient cho tensor này sẽ được tích lũy và xem tại thuộc tính **.grad**.\n",
    "\n",
    "Để dừng theo dõi một tensor chúng ta gọi vào hàm **.detach()**. Khi đó các hoạt động trên tensor sẽ không còn được lưu vết nữa.\n",
    "\n",
    "Ngoài ra để ngăn tensor lưu lại lịch sử (và sử dụng memory), chúng ta cũng có thể bao quanh code block triển khai tensor với hàm **with torch.no_grad()**: nó rất hữu ích trong trường hợp đánh giá model bởi vì khi thuộc tính *requires_grad = True* thì model sẽ có thể được cập nhật tham số. Nhưng **quá trình đánh giá model sẽ không cần cập nhật tham số** nên chúng ta không cần áp dụng gradient lên chúng. Đơn giản là set *requires_grad = False*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 class **Tensor** và **Function** cùng tương tác và xây dựng một đồ thị chu trình mà đồ thị này mã hóa lại toàn bộ lịch sử tính toán. Mỗi một tensor đều có một thuộc tính **grad_fn** trích dẫn đến một **Function** đã tạo ra Tensor (Trừ trường hợp tensor được tạo ra bởi người dùng được set thuộc tính grad_fn là None).\n",
    "\n",
    "Nếu muốn tính toán đạo hàm chúng ta gọi hàm **.backward()** của Tensor. Nếu Tensor là một scalar sẽ không cần xác định bất kỳ đối số **gradient** nào cho .backward(). Tuy nhiên, khi tensor có nhiều hơn 1 phần tử cần xác định đối số **gradient** là một tensor có cùng kích thước. Đối số này sẽ quy định tốc độ thay đổi theo **gradient** tại mỗi chiều là bao nhiêu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minh họa cách tính Gradient tự động trong Pytorch bằng ví dụ sau: Cho đồ thị tính toán như hình. Đầu vào **[x,y,z] = [5,3,7]**. Tất cả các trọng số w đều được khởi tạo là **w=0.5**. Tính kết quả (biến result) khi ta cho [x,y,z] qua mạng (forward) và gradient của mỗi trọng số w (backward).\n",
    "![img](./images/3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "xy = Variable(torch.FloatTensor([5, 3]), requires_grad=True) # size: 2\n",
    "z = Variable(torch.FloatTensor([7]), requires_grad=True)    # size: 1\n",
    "w12 = Variable(torch.FloatTensor([0.5, 0.5]), requires_grad=True)   # size: 2\n",
    "w3 = Variable(torch.FloatTensor([0.5]), requires_grad=True) # size: 1\n",
    "w4 = Variable(torch.FloatTensor([0.5]), requires_grad=True) # size: 1\n",
    "w5 = Variable(torch.FloatTensor([0.5]), requires_grad=True) # size: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 1.5000], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "k = xy*w12\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7500, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "o1 = k[0] * k[1]\n",
    "print(o1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.3750], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "o2 = o1*w4+z*w3\n",
    "print(o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6875], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "result = o2*w5\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w12.grad tensor([1.8750, 1.8750])\n",
      "w3.grad tensor([3.5000])\n",
      "w4.grad tensor([1.8750])\n",
      "w5.grad tensor([5.3750])\n"
     ]
    }
   ],
   "source": [
    "result.backward()\n",
    "print('w12.grad', w12.grad)     # 1.8750, 1.8750\n",
    "print('w3.grad', w3.grad)       # 3.5000\n",
    "print('w4.grad', w4.grad)       # 1.8750\n",
    "print('w5.grad', w5.grad)       # 5.3750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giải thích:\n",
    "\n",
    "**Forward:**\n",
    "- o1 = x * w1 * y * w2 = 5 * 0.5 * 3 * 0.5 = 3.75\n",
    "- o2 = o1 * w4 + z * w3 = 3.75 * 0.5 + 7 * 0.5 = 5.375\n",
    "- result = o2 * w5 = 5.375 * 0.5 = 2.6875\n",
    "\n",
    "**Backward:**\n",
    "- Đạo hàm result theo w5 = (o2 * w5)' = o2 = 5.375\n",
    "- Đạo hàm result theo o2 = w5 = 0.5\n",
    "- Đạo hàm result theo w3 = (o2 * w5)' = ((o1 * w4 + z * w3) * w5)' = z * w5 = 3.5\n",
    "\n",
    "Tương tự cho w4,w1 và w2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
