{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nguồn:\n",
    "1. https://towardsdatascience.com/a-complete-guide-to-using-tensorboard-with-pytorch-53cb2301e8c3\n",
    "2. https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html#adding-a-projector-to-tensorboard\n",
    "3. https://debuggercafe.com/track-your-pytorch-deep-learning-project-with-tensorboard/\n",
    "\n",
    "# Nội dung chính:\n",
    "1. Giới thiệu\n",
    "2. Thiết lập mô hình CNN\n",
    "3. Hiển thị hình ảnh và đồ thị với Tensorboard\n",
    "4. Vòng lặp training để mô phỏng đánh giá\n",
    "5. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Giới thiệu\n",
    "Trong phần này, chúng ta sẽ sử dụng bộ dữ liệu **FashionMNIST** (bao gồm 60000 hình ảnh quần áo và 10 class labels cho các loại quần áo khác nhau) là một dataset trong thư viện **torch vision**. Nó bao gồm các hình ảnh quần áo, giày,... với các nhãn là các số nguyên tương ứng. Chúng ta sẽ tạo một bộ phân loại CNN và rồi rút ra kết luận từ nó. Tuy nhiên, trong bài viết này sẽ giúp bạn mở rộng sức mạnh của Tensorboard cho dự án bất kỳ trong Pytorch mà bạn làm việc sử dụng Custom dataset.\n",
    "\n",
    "Lưu ý rằng bài viết này sẽ không đi sâu vào chi tiết cách thực thi mô hình CNN và setting vòng lặp training. Thay vào đó, tập trung vào các dự án Deep Learning để có được hình ảnh về hoạt động bên trong của các mô hình (**weights** và **bias**) và các chỉ số đánh giá (**loss, độ accuracy, num_correct_predictions**) cùng với điều chỉnh siêu tham số."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "torch.set_printoptions(linewidth=120)\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lệnh cuối cùng bên trên cho phép chúng ta import **Tensorboard**. Chúng ta sẽ tạo instance của **SummaryWriter** và rồi thêm các đặc trưng được tính toán bởi mô hình như loss, số dự đoán đúng, accuracy... vào nó. Một trong những điểm nổi bật của Tensorboard là chúng ta dễ dàng feed các output tensor vào nó và nó hiển thị đồ thị của tất cả các độ đo (metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code trên cho phép chúng ta lấy số labels đúng sau khi training model và apply vào tập test. **argmax** lất chỉ số tương ứng với giá trị cao nhất của một tensor. Lấy tại **dim=1** bởi vì **dim=0** là tương ứng với **batch_size**. Nếu dự đoán đúng với nhãn thật thì sẽ trả lại 1,và ngược lại trả lại 0. Cuối cùng , chúng ta lấy tổng các số 1 là tổng số dự đoán đúng. Sau khi thực hiện các phép toán trên tensor, đầu ra cũng được trả về dưới dạng tensor. Vì vậy chúng ta cần dùng **item** để chuyển tensor về float thông thường trong Python. Khi đó chúng ta có thể append giá trị này vào một list (*total_correct*) để plot trên Tensorboard (Tensor append vào 1 list không thể vẽ trên Tensorboard được)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Thiết lập mô hình CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "        x = torch.flatten(x,start_dim = 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo chúng ta sẽ import data và tạo train loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train = True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=100,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Hiển thị hình ảnh và đồ thị với Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = SummaryWriter()\n",
    "model = CNN()\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb.add_image(\"images\", grid)\n",
    "tb.add_graph(model, images)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta tạo một đối tượng **tb** của **SummaryWriter** và thêm các hình ảnh vào nó bằng cách sử dụng **tb.add_image**. Nó có 2 tham số chính, một là **tiêu đề** của ảnh và **tensor** của ảnh. Trong trường hợp này, chúng ta đã tạo một batch gồm 100 ảnh và passed chúng thành 1 grid rồi thêm vào **tb**. \n",
    "\n",
    "Hàm **tb.add_graph**, chúng ta pass mô hình CNN và một batch đơn vào để sinh đồ thị của mô hình.\n",
    "\n",
    "Sau khi chạy code, thư mục **runs** sẽ được tạo ra. Tất cả tiêu đề đầu trong thư mục sẽ sắp xếp theo **date**. Điều này giúp bạn có thể chạy và so sánh trong Tensorboard.\n",
    "\n",
    "Để chạy tensorboard, chúng ta chạy lệnh sau:\n",
    "\n",
    "> tensorboard --logdir runs\n",
    "\n",
    "Tensorboard sẽ khởi chạy localhost ở cổng nào đó (xem trên cmd) và chúng ta truy cập vào link đó để xem kết quả mô phỏng.\n",
    "\n",
    "Hình ảnh có thể thấy dưới tab **Images**. Chúng ta có thể sử dụng regex để lọc qua các lần chạy và đánh dấu vào những lần chúng ta muốn hình dung.\n",
    "\n",
    "![img](./images/6.png)\n",
    "\n",
    "Ở tab **Graph**, chúng ta sẽ đấy graph của mô hình. Nó cho thấy chi tiết pipeline số chiều của các batch hình ảnh thay đổi như thế nào qua mỗi convolution và layer liner. Nhấn đúp vào để lấy thêm thông tin chi tiết của graph. Nó cũng cung cấp kích thước của tất cả các ma trận trọng số và bias bằng cách nhấp đúp vào bất kỳ lớp Conv2d hoặc Linear nào.\n",
    "\n",
    "![img](./images/7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Vòng lặp training để mô phỏng đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 total_correct: 46570 loss: 357.7504176944494\n",
      "epoch: 1 total_correct: 51260 loss: 238.48734259605408\n",
      "epoch: 2 total_correct: 51914 loss: 220.13289082050323\n",
      "epoch: 3 total_correct: 52380 loss: 207.42743049561977\n",
      "epoch: 4 total_correct: 52720 loss: 197.08434410393238\n",
      "epoch: 5 total_correct: 52813 loss: 196.58541917055845\n",
      "epoch: 6 total_correct: 53044 loss: 189.38912853598595\n",
      "epoch: 7 total_correct: 53052 loss: 187.89532232284546\n",
      "epoch: 8 total_correct: 53216 loss: 186.15575233101845\n",
      "epoch: 9 total_correct: 53163 loss: 187.00692084431648\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=100,\n",
    "    shuffle=True\n",
    ")\n",
    "optimizer = opt.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "tb = SummaryWriter()\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        preds = model(images)\n",
    "        \n",
    "        loss = criterion(preds, labels)\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # For tensorboard\n",
    "    tb.add_scalar(\"Loss\", total_loss, epoch)\n",
    "    tb.add_scalar(\"Correct\", total_correct, epoch)\n",
    "    tb.add_scalar(\"Accuracy\", total_correct/len(train_set), epoch)\n",
    "    \n",
    "    tb.add_histogram(\"conv1.bias\", model.conv1.bias, epoch)\n",
    "    tb.add_histogram(\"conv1.weight\", model.conv1.weight, epoch)\n",
    "    tb.add_histogram(\"conv2.bias\", model.conv2.bias, epoch)\n",
    "    tb.add_histogram(\"conv2.weight\", model.conv2.weight, epoch)\n",
    "    \n",
    "    print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\",\n",
    "         total_loss)\n",
    "    \n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngoài ra, chúng ta cũng có thể sử dụng vòng lặp for để lặp qua tất cả các tham số mô hình bao gồm các lớp fc và softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, weight in model.named_parameters():\n",
    "    tb.add_histogram(name, weight, epoch)\n",
    "    tb.add_histogram(f'{name}.grad', weight.grad, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta chạy vòng lặp 10 epochs.\n",
    "\n",
    "![img](./images/8.png)\n",
    "![img](./images/9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên chúng ta cần thay đổi **batch_size, learning_rate, shuffle** thành các biến động. Chúng ta làm điều này bằng cách tạo dictionary như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01, 0.001], [32, 64, 128], [True, False]]\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "parameters = dict(\n",
    "    lr = [0.01, 0.001],\n",
    "    batch_size = [32, 64, 128],\n",
    "    shuffle = [True, False]\n",
    ")\n",
    "\n",
    "param_values = [v for v in parameters.values()]\n",
    "print(param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 32 True\n",
      "0.01 32 False\n",
      "0.01 64 True\n",
      "0.01 64 False\n",
      "0.01 128 True\n",
      "0.01 128 False\n",
      "0.001 32 True\n",
      "0.001 32 False\n",
      "0.001 64 True\n",
      "0.001 64 False\n",
      "0.001 128 True\n",
      "0.001 128 False\n"
     ]
    }
   ],
   "source": [
    "for lr, batch_size, shuffle in product(*param_values):\n",
    "    print(lr, batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta sẽ có tổng cộng 12 lần chạy với các tham số khác nhau. Chúng ta sẽ sửa lại mô hình huấn luyện như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 1\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 0 total_correct: 47710 loss: 1029.5563011020422\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 1 total_correct: 50464 loss: 810.2039105370641\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 2 total_correct: 50969 loss: 770.8068676441908\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 3 total_correct: 50887 loss: 760.232678130269\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 4 total_correct: 51133 loss: 755.1276897788048\n",
      "__________________________________________________________\n",
      "run id: 2\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 0 total_correct: 47869 loss: 1012.1429817378521\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 1 total_correct: 50685 loss: 794.2090410962701\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 2 total_correct: 51001 loss: 760.5343775339425\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 3 total_correct: 51364 loss: 730.1249665990472\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 4 total_correct: 51555 loss: 715.7606257013977\n",
      "__________________________________________________________\n",
      "run id: 3\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 0 total_correct: 47808 loss: 503.36066749691963\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 1 total_correct: 51357 loss: 367.4209634512663\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 2 total_correct: 52094 loss: 339.16637586802244\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 3 total_correct: 52213 loss: 327.77601147443056\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 4 total_correct: 52519 loss: 319.64979941397905\n",
      "__________________________________________________________\n",
      "run id: 4\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 0 total_correct: 47561 loss: 518.2343814820051\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 1 total_correct: 51039 loss: 377.9226042032242\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 2 total_correct: 51590 loss: 352.8577605187893\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 3 total_correct: 51922 loss: 342.1960898414254\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 4 total_correct: 52060 loss: 334.8932651877403\n",
      "__________________________________________________________\n",
      "run id: 5\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 0 total_correct: 47947 loss: 250.90397353470325\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 1 total_correct: 51985 loss: 170.21379826962948\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 2 total_correct: 52601 loss: 155.2511441707611\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 3 total_correct: 52909 loss: 147.12219999730587\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 4 total_correct: 53102 loss: 144.1638469696045\n",
      "__________________________________________________________\n",
      "run id: 6\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 0 total_correct: 46720 loss: 276.09242182970047\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 1 total_correct: 51436 loss: 183.2309506237507\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 2 total_correct: 52336 loss: 165.0326522886753\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 3 total_correct: 52707 loss: 154.51227316260338\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 4 total_correct: 53033 loss: 149.6045930236578\n",
      "__________________________________________________________\n",
      "run id: 7\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 0 total_correct: 45609 loss: 1177.7757596671581\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 1 total_correct: 51012 loss: 760.3512729331851\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 2 total_correct: 52317 loss: 649.7145641222596\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 3 total_correct: 52866 loss: 596.9319260753691\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 4 total_correct: 53314 loss: 563.5730770956725\n",
      "__________________________________________________________\n",
      "run id: 8\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 0 total_correct: 44484 loss: 1268.3523265719414\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 1 total_correct: 50092 loss: 843.6363736540079\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 2 total_correct: 51649 loss: 716.1551901102066\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 3 total_correct: 52351 loss: 647.4733169823885\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 4 total_correct: 52880 loss: 599.2908804677427\n",
      "__________________________________________________________\n",
      "run id: 9\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 0 total_correct: 43808 loss: 669.9499880373478\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 1 total_correct: 49982 loss: 423.9730204343796\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 2 total_correct: 51650 loss: 358.82705146074295\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 3 total_correct: 52492 loss: 321.556060962379\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 4 total_correct: 52964 loss: 300.0200008228421\n",
      "__________________________________________________________\n",
      "run id: 10\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 0 total_correct: 43233 loss: 691.6303079426289\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 1 total_correct: 49312 loss: 455.0590559542179\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 2 total_correct: 51168 loss: 380.0055624842644\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 3 total_correct: 52088 loss: 339.08402049541473\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 4 total_correct: 52685 loss: 311.6289086267352\n",
      "__________________________________________________________\n",
      "run id: 11\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 0 total_correct: 41167 loss: 392.57962107658386\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 1 total_correct: 47803 loss: 254.99173456430435\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 2 total_correct: 49870 loss: 217.75290903449059\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 3 total_correct: 50950 loss: 197.1842022240162\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 4 total_correct: 51719 loss: 181.40029937028885\n",
      "__________________________________________________________\n",
      "run id: 12\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 0 total_correct: 41623 loss: 380.1151687800884\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 1 total_correct: 47632 loss: 253.54726055264473\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 2 total_correct: 49752 loss: 216.7982075214386\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 3 total_correct: 50984 loss: 194.68367990851402\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 4 total_correct: 51680 loss: 180.07249411940575\n",
      "__________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for run_id, (lr,batch_size, shuffle) in enumerate(product(*param_values)):\n",
    "    print(\"run id:\", run_id + 1)\n",
    "    model = CNN().to(device)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set,batch_size = batch_size, shuffle = shuffle)\n",
    "    optimizer = opt.Adam(model.parameters(), lr= lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    comment = f' batch_size = {batch_size} lr = {lr} shuffle = {shuffle}'\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "    for epoch in range(5):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            preds = model(images)\n",
    "\n",
    "            loss = criterion(preds, labels)\n",
    "            total_loss+= loss.item()\n",
    "            total_correct+= get_num_correct(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        tb.add_scalar(\"Loss\", total_loss, epoch)\n",
    "        tb.add_scalar(\"Correct\", total_correct, epoch)\n",
    "        tb.add_scalar(\"Accuracy\", total_correct/ len(train_set), epoch)\n",
    "\n",
    "        print(\"batch_size:\",batch_size, \"lr:\",lr,\"shuffle:\",shuffle)\n",
    "        print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\",total_loss)\n",
    "    print(\"__________________________________________________________\")\n",
    "\n",
    "    tb.add_hparams(\n",
    "            {\"lr\": lr, \"bsize\": batch_size, \"shuffle\":shuffle},\n",
    "            {\n",
    "                \"accuracy\": total_correct/ len(train_set),\n",
    "                \"loss\": total_loss,\n",
    "            },\n",
    "        )\n",
    "\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như đã thấy ở trên, mình đã di chuyển mọi thứ theo vòng lặp for để xem xét tất cả các kết hợp khác nhau của các siêu tham số và tại mỗi lần chạy. Chúng ta phải khởi tạo lại mô hình cũng như tải lại các batches của tập dữ liệu. **comment** cho phép tạo các thư mục khác nhau ở trong folder **runs** phụ thuộc vào siêu tham số. Chúng ta pass comment vào **SummaryWriter**. Lưu ý rằng chúng ta sẽ xem tất cả các runs chạy vào so sánh tất cả các siêu tham số trong Tensorboard.\n",
    "\n",
    "* **tb.add_scalar** giống như trước đó chỉ là chúng tôi hiển thị nó cho tất cả các lần chạy.\n",
    "* **tb.add_hparams** cho phép thêm các siêu tham số bên trong là các đối số để theo dõi tiến trình đào tạo.\n",
    "\n",
    "Cần có hai dict làm đầu vào, một cho siêu tham số và một dict khác để phân tích các chỉ số đánh giá.  Kết quả được ánh xạ trên tất cả các siêu tham số này.  Nó sẽ rõ ràng từ sơ đồ ánh xạ đồ thị ở phía dưới."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./images/10.png)\n",
    "![img](./images/11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "các vấn đề về Tensorboard trong Pytorch các bạn có thể xem thêm tại: https://pytorch.org/docs/stable/tensorboard.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
