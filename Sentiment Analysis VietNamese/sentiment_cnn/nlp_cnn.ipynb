{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phân loại sắc thái bình luận bằng mô hình CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dữ liệu (Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nguồn: Cuộc thi phân loại sắc thái bình luận của aivivn `https://www.aivivn.com/contests/1`\n",
    "\n",
    "Mô tả: 3(file): file_train: train.crash, file test: test.crash, sample_submission.csv.\n",
    "\n",
    "Dữ liệu: Câu bình luận có độ dài bất kỳ được gán nhãn 0 hoặc 1, trong đó 1: bình luận tiêu cực, 0: bình luận tích cực\n",
    "\n",
    "train.crash: 16086, test.crash: 10980\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tổng quan về phương pháp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước 1. Tiền xử lý dữ liệu: lấy được các trường dữ liệu: `id, label, review`\n",
    "\n",
    "Bước 2. Sử dụng `FastText` để `Word Embedding`: biểu diễn mỗi từ là vector có 50 phần tử.\n",
    "\n",
    "Bước 3. Chuẩn hóa độ dài các câu trong dữ liệu train `len(max(review)) = 679`. Thêm các từ viền PAD.\n",
    "\n",
    "Bước 4. Đưa vào mô hình CNN: `Conv1D`, `optimizer='adam'`.\n",
    "\n",
    "Bước 5. Predict với dữ liệu `validation_data`.\n",
    "\n",
    "Bước 6. Predict với dữ liệu `test`.\n",
    "\n",
    "Bước 7. Đánh giá độ chính xác và kết luận."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Xây dựng mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lấy các trường dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_row(sample):        \n",
    "        d = {}\n",
    "        d['id'] = sample[0].replace('\\n','')\n",
    "        review = \"\"\n",
    "\n",
    "        for clause in sample[1:-1]:\n",
    "            review+= clause.replace('\\n','').strip()\n",
    "        d['label'] = int(sample[-1].replace('\\n',''))\n",
    "            \n",
    "        d['review'] = review\n",
    "        return d\n",
    "    \n",
    "def _load_raw_data():\n",
    "    a = []\n",
    "    b = []\n",
    "    with open('./data/train.crash', 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            if 'train_' in line:\n",
    "                b.append(a)\n",
    "                a = [line]  \n",
    "            elif line!='\\n':\n",
    "                a.append(line) \n",
    "        b.append(a)\n",
    "    return b[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['train_000000\\n',\n",
       "  '\"Dung dc sp tot cam on \\n',\n",
       "  'shop Đóng gói sản phẩm rất đẹp và chắc chắn Chất lượng sản phẩm tuyệt vời\"\\n',\n",
       "  '0\\n'],\n",
       " ['train_000001\\n',\n",
       "  '\" Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh\"\\n',\n",
       "  '0\\n'],\n",
       " ['train_000002\\n',\n",
       "  '\" Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất\"\\n',\n",
       "  '0\\n']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = _load_raw_data()\n",
    "raw_data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for row in raw_data:\n",
    "    lst.append(_create_row(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'train_000001',\n",
       "  'label': 0,\n",
       "  'review': '\" Chất lượng sản phẩm tuyệt vời . Son mịn nhưng khi đánh lên không như màu trên ảnh\"'},\n",
       " {'id': 'train_000002',\n",
       "  'label': 0,\n",
       "  'review': '\" Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất\"'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token các từ trong bình luận"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nltk) (1.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for l in lst:\n",
    "    tokens_line = nltk.word_tokenize(l['review'][1:-2].lower())\n",
    "    X_train.append(tokens_line)\n",
    "    y_train.append([l['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dung',\n",
       "  'dc',\n",
       "  'sp',\n",
       "  'tot',\n",
       "  'cam',\n",
       "  'onshop',\n",
       "  'đóng',\n",
       "  'gói',\n",
       "  'sản',\n",
       "  'phẩm',\n",
       "  'rất',\n",
       "  'đẹp',\n",
       "  'và',\n",
       "  'chắc',\n",
       "  'chắn',\n",
       "  'chất',\n",
       "  'lượng',\n",
       "  'sản',\n",
       "  'phẩm',\n",
       "  'tuyệt',\n",
       "  'vờ'],\n",
       " ['chất',\n",
       "  'lượng',\n",
       "  'sản',\n",
       "  'phẩm',\n",
       "  'tuyệt',\n",
       "  'vời',\n",
       "  '.',\n",
       "  'son',\n",
       "  'mịn',\n",
       "  'nhưng',\n",
       "  'khi',\n",
       "  'đánh',\n",
       "  'lên',\n",
       "  'không',\n",
       "  'như',\n",
       "  'màu',\n",
       "  'trên',\n",
       "  'ản'],\n",
       " ['chất',\n",
       "  'lượng',\n",
       "  'sản',\n",
       "  'phẩm',\n",
       "  'tuyệt',\n",
       "  'vời',\n",
       "  'nhưng',\n",
       "  'k',\n",
       "  'có',\n",
       "  'hộp',\n",
       "  'k',\n",
       "  'có',\n",
       "  'dây',\n",
       "  'giày',\n",
       "  'đen',\n",
       "  'k',\n",
       "  'có',\n",
       "  'tấ']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biểu diễn các từ thành các vector độ dài 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "num_features = 50 # số phần tử vector từ để biểu diễn từ\n",
    "model = FastText(X_train, size = num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tốt..', 0.9387295246124268),\n",
       " ('tố', 0.9257695078849792),\n",
       " ('tốtrất', 0.8866126537322998),\n",
       " ('tốtthời', 0.8539071083068848),\n",
       " ('chắn.shop', 0.8306227326393127),\n",
       " ('vụ', 0.8274441957473755),\n",
       " ('chắnshop', 0.8272778391838074),\n",
       " ('chắnthời', 0.7971609234809875),\n",
       " ('chắnrất', 0.7832304239273071),\n",
       " ('nhanh.shop', 0.7824429869651794)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word(\"tốt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7861665 ,  0.3493711 , -1.4547497 ,  0.30683073,  0.2967116 ,\n",
       "       -0.15043758, -0.49263048, -2.4581242 ,  0.0238688 ,  0.50196725,\n",
       "       -1.6451759 , -0.03142986,  1.5748236 ,  0.8722173 ,  0.59551466,\n",
       "        1.3626158 ,  0.8051109 , -1.0753506 ,  0.35939068,  0.52111614,\n",
       "        0.11620174,  0.0551413 ,  1.5276858 ,  0.0726677 , -0.17386746,\n",
       "        1.0182841 , -0.58345735,  0.24316444, -0.02629043, -0.04641446,\n",
       "        0.4349537 ,  0.72265255,  0.4430185 , -0.1334187 ,  0.41484886,\n",
       "        1.5819662 ,  1.8601044 ,  0.6961471 , -1.1983576 ,  0.7633791 ,\n",
       "       -1.141518  ,  0.82182556,  0.87123686,  0.93413454,  2.6408226 ,\n",
       "       -0.2873781 ,  2.1390705 ,  2.4530299 ,  0.21077135,  0.7954732 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"tốt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "679"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_max_sen = max([len(x) for x in X_train])\n",
    "len_max_sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Độ dài câu dài nhất trong X_train là `679`. Chúng ta sẽ coi mỗi câu có độ dài như nhau là 679 (để đưa vào mô hình được thì phải thống nhất kích thước). Mỗi từ được biểu diễn qua model FastText đã train, với những câu không đủ độ dài 679, chúng ta thêm các từ `PAD` và coi đó là từ viền cho 1 câu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Thêm các từ PAD: từ viền cho 1 câu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = []\n",
    "for sent in X_train:\n",
    "    temp = sent\n",
    "    # thêm PAD\n",
    "    if len(sent) < len_max_sen:\n",
    "        add_element = len_max_sen - len(sent)\n",
    "        for _ in range(add_element):\n",
    "            temp.append('PAD')\n",
    "    # vector hoá\n",
    "    for i in range(len(sent)):\n",
    "        sent[i] = model.wv[sent[i]]\n",
    "    X_train_num.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Lấy khoảng 10k câu để train\n",
    "X_train_num = np.array(X_train_num[:10000])\n",
    "y_train_num = np.array(y_train[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 679, 50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_num.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 677, 32)           4832      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 675, 32)           3104      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               5400250   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 5,408,437\n",
      "Trainable params: 5,408,437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, Flatten\n",
    "\n",
    "maxlen = 679\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 32\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "\n",
    "CNN = Sequential()\n",
    "CNN.add(Conv1D(filters, kernel_size, padding='valid', activation='relu', strides=1, input_shape=(maxlen, embedding_dims)))\n",
    "CNN.add(Conv1D(filters, kernel_size, padding='valid', activation='relu', strides=1))\n",
    "CNN.add(Flatten())\n",
    "CNN.add(Dense(hidden_dims, activation='relu'))\n",
    "CNN.add(Dropout(0.2))\n",
    "CNN.add(Dense(1, activation='sigmoid'))\n",
    "CNN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.array(X_train[10000:])\n",
    "y_val = np.array(y_train[10000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 10000 samples, validate on 6087 samples\n",
      "Epoch 1/5\n",
      "10000/10000 [==============================] - 75s 8ms/step - loss: 0.3689 - accuracy: 0.8311 - val_loss: 0.3182 - val_accuracy: 0.8630\n",
      "Epoch 2/5\n",
      "10000/10000 [==============================] - 61s 6ms/step - loss: 0.2975 - accuracy: 0.8713 - val_loss: 0.3397 - val_accuracy: 0.8543\n",
      "Epoch 3/5\n",
      "10000/10000 [==============================] - 63s 6ms/step - loss: 0.2640 - accuracy: 0.8889 - val_loss: 0.3197 - val_accuracy: 0.8643\n",
      "Epoch 4/5\n",
      "10000/10000 [==============================] - 60s 6ms/step - loss: 0.2320 - accuracy: 0.9002 - val_loss: 0.3246 - val_accuracy: 0.8671\n",
      "Epoch 5/5\n",
      "10000/10000 [==============================] - 56s 6ms/step - loss: 0.2047 - accuracy: 0.9132 - val_loss: 0.3541 - val_accuracy: 0.8668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19f956d8588>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "CNN.fit(X_train_num ,y_train_num, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.save(\"model.h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = CNN.evaluate(X_val, y_val, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3540663365735203, 0.8667652606964111]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
