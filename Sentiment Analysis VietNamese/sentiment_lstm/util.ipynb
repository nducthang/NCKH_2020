{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyvi import ViTokenizer\n",
    "import re\n",
    "import string\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·ª´ ƒëi·ªÉn t√≠ch c·ª±c, ti√™u c·ª±c, ph·ªß ƒë·ªãnh\n",
    "path_nag = 'sentiment_dicts/nag.txt'\n",
    "path_pos = 'sentiment_dicts/pos.txt'\n",
    "path_not = 'sentiment_dicts/not.txt'\n",
    "\n",
    "VN_CHARS_LOWER = u'·∫°·∫£√£√†√°√¢·∫≠·∫ß·∫•·∫©·∫´ƒÉ·∫Ø·∫±·∫∑·∫≥·∫µ√≥√≤·ªç√µ·ªè√¥·ªô·ªï·ªó·ªì·ªë∆°·ªù·ªõ·ª£·ªü·ª°√©√®·∫ª·∫π·∫Ω√™·∫ø·ªÅ·ªá·ªÉ·ªÖ√∫√π·ª•·ªß≈©∆∞·ª±·ªØ·ª≠·ª´·ª©√≠√¨·ªã·ªâƒ©√Ω·ª≥·ª∑·ªµ·ªπƒë√∞'\n",
    "VN_CHARS_UPPER = u'·∫†·∫¢√É√Ä√Å√Ç·∫¨·∫¶·∫§·∫®·∫™ƒÇ·∫Æ·∫∞·∫∂·∫≤·∫¥√ì√í·ªå√ï·ªé√î·ªò·ªî·ªñ·ªí·ªê∆†·ªú·ªö·ª¢·ªû·ª†√â√à·∫∫·∫∏·∫º√ä·∫æ·ªÄ·ªÜ·ªÇ·ªÑ√ö√ô·ª§·ª¶≈®∆Ø·ª∞·ªÆ·ª¨·ª™·ª®√ç√å·ªä·ªàƒ®√ù·ª≤·ª∂·ª¥·ª∏√êƒê'\n",
    "VN_CHARS = VN_CHARS_LOWER + VN_CHARS_UPPER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ƒê∆∞a ra m·ªôt chu·ªói c√°c t·ª´ ƒëi·ªÉn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diction_nag_pos_not():\n",
    "    with codecs.open(path_nag, 'r', encoding='UTF-8') as f:\n",
    "        nag = f.readlines()\n",
    "    nag_list = [n.replace('\\n', '') for n in nag]\n",
    "\n",
    "    with codecs.open(path_pos, 'r', encoding='UTF-8') as f:\n",
    "        pos = f.readlines()\n",
    "    pos_list = [n.replace('\\n', '') for n in pos]\n",
    "    with codecs.open(path_not, 'r', encoding='UTF-8') as f:\n",
    "        not_ = f.readlines()\n",
    "    not_list = [n.replace('\\n', '') for n in not_]\n",
    "    return nag_list, pos_list, not_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nag_list, pos_list, not_list = diction_nag_pos_not()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ch√°n',\n",
       " 'ch·∫≠t h·∫πch·∫≠t',\n",
       " 'ch·∫≠t',\n",
       " 't·ª©c gi·∫≠n',\n",
       " 'x·∫•u',\n",
       " 'kh·ªßng khi·∫øp',\n",
       " 'm·ªèng',\n",
       " 'nh·∫ßm',\n",
       " 'ƒëe d·ªça']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nag_list[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['∆∞ng', 'k·ªπ', 'ƒë∆∞·ª£c', '√¥ k√™', 'ok', 'm·ªãn', '·ªïn', 'xinh', 'ch√∫c m·ª´ng']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_list[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v√¥', 'ch·∫≥ng', 'ƒë·∫øch', 'ch∆∞a', 'ƒë√©o', 'k√©m', 'n·ªè', 'not']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_list[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H√†m b·ªè d·∫•u cho text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_marks(s):\n",
    "    __INTAB = [ch for ch in VN_CHARS]\n",
    "    __OUTTAB = \"a\" * 17 + \"o\" * 17 + \"e\" * 11 + \"u\" * 11 + \"i\" * 5 + \"y\" * 5 + \"d\" * 2\n",
    "    __OUTTAB += \"A\" * 17 + \"O\" * 17 + \"E\" * 11 + \"U\" * 11 + \"I\" * 5 + \"Y\" * 5 + \"D\" * 2\n",
    "    __r = re.compile(\"|\".join(__INTAB))\n",
    "    __replaces_dict = dict(zip(__INTAB, __OUTTAB))\n",
    "    result = __r.sub(lambda m: __replaces_dict[m.group(0)], s)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H√†m chu·∫©n h√≥a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    # Remove c√°c k√Ω t·ª± k√©o d√†i: vd: ƒë·∫πppppppp\n",
    "    text = re.sub(r'([A-Z])\\1+', lambda m: m.group(1).upper(), text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Chuy·ªÉn th√†nh ch·ªØ th∆∞·ªùng\n",
    "    text = text.lower()\n",
    "\n",
    "    # Chu·∫©n h√≥a ti·∫øng Vi·ªát, x·ª≠ l√Ω emoj, chu·∫©n h√≥a ti·∫øng Anh, thu·∫≠t ng·ªØ\n",
    "    replace_list = {\n",
    "        '√≤a': 'o√†', '√≥a': 'o√°', '·ªèa': 'o·∫£', '√µa': 'o√£', '·ªça': 'o·∫°', '√≤e': 'o√®', '√≥e': 'o√©', '·ªèe': 'o·∫ª',\n",
    "        '√µe': 'o·∫Ω', '·ªçe': 'o·∫π', '√πy': 'u·ª≥', '√∫y': 'u√Ω', '·ªßy': 'u·ª∑', '≈©y': 'u·ªπ', '·ª•y': 'u·ªµ', 'u·∫£': '·ªßa',\n",
    "        'aÃâ': '·∫£', '√¥ÃÅ': '·ªë', 'u¬¥': '·ªë', '√¥ÃÉ': '·ªó', '√¥ÃÄ': '·ªì', '√¥Ãâ': '·ªï', '√¢ÃÅ': '·∫•', '√¢ÃÉ': '·∫´', '√¢Ãâ': '·∫©',\n",
    "        '√¢ÃÄ': '·∫ß', 'oÃâ': '·ªè', '√™ÃÄ': '·ªÅ', '√™ÃÉ': '·ªÖ', 'ƒÉÃÅ': '·∫Ø', 'uÃâ': '·ªß', '√™ÃÅ': '·∫ø', '∆°Ãâ': '·ªü', 'iÃâ': '·ªâ',\n",
    "        'eÃâ': '·∫ª', '√†k': u' √† ', 'aÀã': '√†', 'iÀã': '√¨', 'ƒÉ¬¥': '·∫Ø', '∆∞Ãâ': '·ª≠', 'eÀú': '·∫Ω', 'yÀú': '·ªπ', 'a¬¥': '√°',\n",
    "        # Quy c√°c icon v·ªÅ 2 lo·∫°i emoj: T√≠ch c·ª±c ho·∫∑c ti√™u c·ª±c\n",
    "        \"üëπ\": \"nagative\", \"üëª\": \"positive\", \"üíÉ\": \"positive\", 'ü§ô': ' positive ', 'üëç': ' positive ',\n",
    "        \"üíÑ\": \"positive\", \"üíé\": \"positive\", \"üí©\": \"positive\", \"üòï\": \"nagative\", \"üò±\": \"nagative\", \"üò∏\": \"positive\",\n",
    "        \"üòæ\": \"nagative\", \"üö´\": \"nagative\", \"ü§¨\": \"nagative\", \"üßö\": \"positive\", \"üß°\": \"positive\", 'üê∂': ' positive ',\n",
    "        'üëé': ' nagative ', 'üò£': ' nagative ', '‚ú®': ' positive ', '‚ù£': ' positive ', '‚òÄ': ' positive ',\n",
    "        '‚ô•': ' positive ', 'ü§©': ' positive ', 'like': ' positive ', 'üíå': ' positive ',\n",
    "        'ü§£': ' positive ', 'üñ§': ' positive ', 'ü§§': ' positive ', ':(': ' nagative ', 'üò¢': ' nagative ',\n",
    "        '‚ù§': ' positive ', 'üòç': ' positive ', 'üòò': ' positive ', 'üò™': ' nagative ', 'üòä': ' positive ',\n",
    "        '?': ' ? ', 'üòÅ': ' positive ', 'üíñ': ' positive ', 'üòü': ' nagative ', 'üò≠': ' nagative ',\n",
    "        'üíØ': ' positive ', 'üíó': ' positive ', '‚ô°': ' positive ', 'üíú': ' positive ', 'ü§ó': ' positive ',\n",
    "        '^^': ' positive ', 'üò®': ' nagative ', '‚ò∫': ' positive ', 'üíã': ' positive ', 'üëå': ' positive ',\n",
    "        'üòñ': ' nagative ', 'üòÄ': ' positive ', ':((': ' nagative ', 'üò°': ' nagative ', 'üò†': ' nagative ',\n",
    "        'üòí': ' nagative ', 'üôÇ': ' positive ', 'üòè': ' nagative ', 'üòù': ' positive ', 'üòÑ': ' positive ',\n",
    "        'üòô': ' positive ', 'üò§': ' nagative ', 'üòé': ' positive ', 'üòÜ': ' positive ', 'üíö': ' positive ',\n",
    "        '‚úå': ' positive ', 'üíï': ' positive ', 'üòû': ' nagative ', 'üòì': ' nagative ', 'Ô∏èüÜóÔ∏è': ' positive ',\n",
    "        'üòâ': ' positive ', 'üòÇ': ' positive ', ':v': '  positive ', '=))': '  positive ', 'üòã': ' positive ',\n",
    "        'üíì': ' positive ', 'üòê': ' nagative ', ':3': ' positive ', 'üò´': ' nagative ', 'üò•': ' nagative ',\n",
    "        'üòÉ': ' positive ', 'üò¨': ' üò¨ ', 'üòå': ' üòå ', 'üíõ': ' positive ', 'ü§ù': ' positive ', 'üéà': ' positive ',\n",
    "        'üòó': ' positive ', 'ü§î': ' nagative ', 'üòë': ' nagative ', 'üî•': ' nagative ', 'üôè': ' nagative ',\n",
    "        'üÜó': ' positive ', 'üòª': ' positive ', 'üíô': ' positive ', 'üíü': ' positive ',\n",
    "        'üòö': ' positive ', '‚ùå': ' nagative ', 'üëè': ' positive ', ';)': ' positive ', '<3': ' positive ',\n",
    "        'üåù': ' positive ', 'üå∑': ' positive ', 'üå∏': ' positive ', 'üå∫': ' positive ',\n",
    "        'üåº': ' positive ', 'üçì': ' positive ', 'üêÖ': ' positive ', 'üêæ': ' positive ', 'üëâ': ' positive ',\n",
    "        'üíê': ' positive ', 'üíû': ' positive ', 'üí•': ' positive ', 'üí™': ' positive ',\n",
    "        'üí∞': ' positive ', 'üòá': ' positive ', 'üòõ': ' positive ', 'üòú': ' positive ',\n",
    "        'üôÉ': ' positive ', 'ü§ë': ' positive ', 'ü§™': ' positive ', '‚òπ': ' nagative ', 'üíÄ': ' nagative ',\n",
    "        'üòî': ' nagative ', 'üòß': ' nagative ', 'üò©': ' nagative ', 'üò∞': ' nagative ', 'üò≥': ' nagative ',\n",
    "        'üòµ': ' nagative ', 'üò∂': ' nagative ', 'üôÅ': ' nagative ',\n",
    "        # Chu·∫©n h√≥a 1 s·ªë sentiment words/English words\n",
    "        ':))': '  positive ', ':)': ' positive ', '√¥ k√™i': ' ok ', 'okie': ' ok ', ' o k√™ ': ' ok ',\n",
    "        'okey': ' ok ', '√¥k√™': ' ok ', 'oki': ' ok ', ' oke ': ' ok ', ' okay': ' ok ', 'ok√™': ' ok ',\n",
    "        ' tks ': u' c√°m ∆°n ', 'thks': u' c√°m ∆°n ', 'thanks': u' c√°m ∆°n ', 'ths': u' c√°m ∆°n ', 'thank': u' c√°m ∆°n ',\n",
    "        '‚≠ê': 'star ', '*': 'star ', 'üåü': 'star ', 'üéâ': u' positive ',\n",
    "        'kg ': u' kh√¥ng ', 'not': u' kh√¥ng ', u' kg ': u' kh√¥ng ', '\"k ': u' kh√¥ng ', ' kh ': u' kh√¥ng ',\n",
    "        'k√¥': u' kh√¥ng ', 'hok': u' kh√¥ng ', ' kp ': u' kh√¥ng ph·∫£i ', u' k√¥ ': u' kh√¥ng ', '\"ko ': u' kh√¥ng ',\n",
    "        u' ko ': u' kh√¥ng ', u' k ': u' kh√¥ng ', 'khong': u' kh√¥ng ', u' hok ': u' kh√¥ng ',\n",
    "        'he he': ' positive ', 'hehe': ' positive ', 'hihi': ' positive ', 'haha': ' positive ', 'hjhj': ' positive ',\n",
    "        ' lol ': ' nagative ', ' cc ': ' nagative ', 'cute': u' d·ªÖ th∆∞∆°ng ', 'huhu': ' nagative ', ' vs ': u' v·ªõi ',\n",
    "        'wa': ' qu√° ', 'w√°': u' qu√°', 'j': u' g√¨ ', '‚Äú': ' ',\n",
    "        ' sz ': u' c·ª° ', 'size': u' c·ª° ', u' ƒëx ': u' ƒë∆∞·ª£c ', 'dk': u' ƒë∆∞·ª£c ', 'dc': u' ƒë∆∞·ª£c ', 'ƒëk': u' ƒë∆∞·ª£c ',\n",
    "        'ƒëc': u' ƒë∆∞·ª£c ', 'authentic': u' chu·∫©n ch√≠nh h√£ng ', u' aut ': u' chu·∫©n ch√≠nh h√£ng ',\n",
    "        u' auth ': u' chu·∫©n ch√≠nh h√£ng ', 'thick': u' positive ', 'store': u' c·ª≠a h√†ng ',\n",
    "        'shop': u' c·ª≠a h√†ng ', 'sp': u' s·∫£n ph·∫©m ', 'gud': u' t·ªët ', 'god': u' t·ªët ', 'wel done': ' t·ªët ',\n",
    "        'good': u' t·ªët ', 'g√∫t': u' t·ªët ',\n",
    "        's·∫•u': u' x·∫•u ', 'gut': u' t·ªët ', u' tot ': u' t·ªët ', u' nice ': u' t·ªët ', 'perfect': 'r·∫•t t·ªët',\n",
    "        'bt': u' b√¨nh th∆∞·ªùng ',\n",
    "        'time': u' th·ªùi gian ', 'q√°': u' qu√° ', u' ship ': u' giao h√†ng ', u' m ': u' m√¨nh ', u' mik ': u' m√¨nh ',\n",
    "        '√™Ãâ': '·ªÉ', 'product': 's·∫£n ph·∫©m', 'quality': 'ch·∫•t l∆∞·ª£ng', 'chat': ' ch·∫•t ', 'excelent': 'ho√†n h·∫£o',\n",
    "        'bad': 't·ªá', 'fresh': ' t∆∞∆°i ', 'sad': ' t·ªá ',\n",
    "        'date': u' h·∫°n s·ª≠ d·ª•ng ', 'hsd': u' h·∫°n s·ª≠ d·ª•ng ', 'quickly': u' nhanh ', 'quick': u' nhanh ',\n",
    "        'fast': u' nhanh ', 'delivery': u' giao h√†ng ', u' s√≠p ': u' giao h√†ng ',\n",
    "        'beautiful': u' ƒë·∫πp tuy·ªát v·ªùi ', u' tl ': u' tr·∫£ l·ªùi ', u' r ': u' r·ªìi ', u' shopE ': u' c·ª≠a h√†ng ',\n",
    "        u' order ': u' ƒë·∫∑t h√†ng ',\n",
    "        'ch·∫•t lg': u' ch·∫•t l∆∞·ª£ng ', u' sd ': u' s·ª≠ d·ª•ng ', u' dt ': u' ƒëi·ªán tho·∫°i ', u' nt ': u' nh·∫Øn tin ',\n",
    "        u' tl ': u' tr·∫£ l·ªùi ', u' s√†i ': u' x√†i ', u'bjo': u' bao gi·ªù ',\n",
    "        'thik': u' th√≠ch ', u' sop ': u' c·ª≠a h√†ng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' r·∫•t ',\n",
    "        u'qu·∫£ ng ': u' qu·∫£ng  ',\n",
    "        'dep': u' ƒë·∫πp ', u' xau ': u' x·∫•u ', 'delicious': u' ngon ', u'h√†g': u' h√†ng ', u'q·ªßa': u' qu·∫£ ',\n",
    "        'iu': u' y√™u ', 'fake': u' gi·∫£ m·∫°o ', 'trl': 'tr·∫£ l·ªùi', '><': u' positive ',\n",
    "        ' por ': u' t·ªá ', ' poor ': u' t·ªá ', 'ib': u' nh·∫Øn tin ', 'rep': u' tr·∫£ l·ªùi ', u'fback': ' feedback ',\n",
    "        'fedback': ' feedback ',\n",
    "        # d∆∞·ªõi 3* quy v·ªÅ 1*, tr√™n 3* quy v·ªÅ 5*\n",
    "        '6 sao': ' 5star ', '6 star': ' 5star ', '5star': ' 5star ', '5 sao': ' 5star ', '5sao': ' 5star ',\n",
    "        'starstarstarstarstar': ' 5star ', '1 sao': ' 1star ', '1sao': ' 1star ', '2 sao': ' 1star ', '2sao': ' 1star ',\n",
    "        '2 starstar': ' 1star ', '1star': ' 1star ', '0 sao': ' 1star ', '0star': ' 1star ', }\n",
    "\n",
    "    for k, v in replace_list.items():\n",
    "        text = text.replace(k, v)\n",
    "\n",
    "    # chuyen punctuation th√†nh space\n",
    "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    text = ViTokenizer.tokenize(text)\n",
    "    texts = text.split()\n",
    "    len_text = len(texts)\n",
    "    nag_list, pos_list, not_list = diction_nag_pos_not()\n",
    "    texts = [t.replace('_', ' ') for t in texts]\n",
    "    for i in range(len_text):\n",
    "        cp_text = texts[i]\n",
    "        if cp_text in not_list:  # X·ª≠ l√Ω v·∫•n ƒë·ªÅ ph·ªß ƒë·ªãnh (VD: √°o n√†y ch·∫≥ng ƒë·∫πp--> √°o n√†y notpos)\n",
    "            numb_word = 2 if len_text - i - 1 >= 4 else len_text - i - 1\n",
    "\n",
    "            for j in range(numb_word):\n",
    "                if texts[i + j + 1] in pos_list:\n",
    "                    texts[i] = 'notpos'\n",
    "                    texts[i + j + 1] = ''\n",
    "\n",
    "                if texts[i + j + 1] in nag_list:\n",
    "                    texts[i] = 'notnag'\n",
    "                    texts[i + j + 1] = ''\n",
    "        else:  # Th√™m feature cho nh·ªØng sentiment words (√°o n√†y ƒë·∫πp--> √°o n√†y ƒë·∫πp positive)\n",
    "            if cp_text in pos_list:\n",
    "                texts.append('positive')\n",
    "            elif cp_text in nag_list:\n",
    "                texts.append('nagative')\n",
    "\n",
    "    text = u' '.join(texts)\n",
    "\n",
    "    # remove n·ªët nh·ªØng k√Ω t·ª± th·ª´a th√£i\n",
    "    text = text.replace(u'\"', u' ')\n",
    "    text = text.replace(u'Ô∏è', u'')\n",
    "    text = text.replace('üèª', '')\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '√°o n√†y quaa ƒë·∫πp'\n",
    "text = normalize_text(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSource(object):\n",
    "    def _load_raw_data(self, filename, is_train=True):\n",
    "        a = []\n",
    "        b = []\n",
    "        regex = 'train_'\n",
    "        if not is_train:\n",
    "            regex = 'test_'\n",
    "        with open(filename, 'r', encoding='utf8') as file:\n",
    "            for line in file:\n",
    "                if regex in line:\n",
    "                    b.append(a)\n",
    "                    a = [line]\n",
    "                elif line != '\\n':\n",
    "                    a.append(line)\n",
    "        b.append(a)\n",
    "        return b[1:]\n",
    "\n",
    "    def _create_row(self, sample, is_train=True):\n",
    "        d = {}\n",
    "        d['id'] = sample[0].replace('\\n', '')\n",
    "        review = \"\"\n",
    "        if is_train:\n",
    "            for clause in sample[1:-1]:\n",
    "                review += clause.replace('\\n', '').strip()\n",
    "            d['label'] = int(sample[-1].replace('\\n', ''))\n",
    "        else:\n",
    "            for clause in sample[1:]:\n",
    "                review += clause.replace('\\n', '').strip()\n",
    "        d['review'] = review\n",
    "        return d\n",
    "\n",
    "    def load_data(self, filename, is_train=True):\n",
    "\n",
    "        raw_data = self._load_raw_data(filename, is_train)\n",
    "        lst = []\n",
    "\n",
    "        for row in raw_data:\n",
    "            lst.append(self._create_row(row, is_train))\n",
    "\n",
    "        return lst\n",
    "\n",
    "    def transform_to_dataset(self, x_set, y_set):\n",
    "        X, y = [], []\n",
    "        for document, topic in zip(list(x_set), list(y_set)):\n",
    "            document = normalize_text(document)\n",
    "            X.append(document.strip())\n",
    "            y.append(topic)\n",
    "            # Augmentation b·∫±ng c√°ch remove d·∫•u ti·∫øng Vi·ªát\n",
    "            X.append(no_marks(document))\n",
    "            y.append(topic)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S·ª≠ d·ª•ng model ƒë·ªÉ train d·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_data():\n",
    "    ds = DataSource()\n",
    "    train_data = pd.DataFrame(ds.load_data(file_name))\n",
    "    new_data = []\n",
    "\n",
    "    # Th√™m m·∫´u b·∫±ng c√°ch l·∫•y trong t·ª´ ƒëi·ªÉn Sentiment (nag/pos)\n",
    "    nag_list, pos_list, not_list = diction_nag_pos_not()\n",
    "    for index, row in enumerate(pos_list):\n",
    "        new_data.append(['pos' + str(index), '0', row])\n",
    "    for index, row in enumerate(nag_list):\n",
    "        new_data.append(['nag' + str(index), '1', row])\n",
    "\n",
    "    new_data = pd.DataFrame(new_data, columns=list(['id', 'label', 'review']))\n",
    "    train_data = train_data.append(new_data, ignore_index=True)\n",
    "    test_data = pd.DataFrame(ds.load_data('data/test.crash', is_train=False))\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'C:/Users/Admin/Desktop/ML/Ph√¢n lo·∫°i s·∫Øc th√°i b√¨nh lu·∫≠n/sentiment_lstm/data/train.crash'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = return_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_000000</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Dung dc sp tot cam onshop ƒê√≥ng g√≥i s·∫£n ph·∫©m r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi . Son m·ªãn nh∆∞n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_000002</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi nh∆∞ng k c√≥ h·ªôp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_000003</td>\n",
       "      <td>1</td>\n",
       "      <td>\":(( M√¨nh h∆°i th·∫•t v·ªçng 1 ch√∫t v√¨ m√¨nh ƒë√£ k·ª≥ v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_000004</td>\n",
       "      <td>1</td>\n",
       "      <td>\"L·∫ßn tr∆∞·ªõc m√¨nh mua √°o gi√≥ m√†u h·ªìng r·∫•t ok m√† ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16524</th>\n",
       "      <td>nag259</td>\n",
       "      <td>1</td>\n",
       "      <td>l·ªôn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16525</th>\n",
       "      <td>nag260</td>\n",
       "      <td>1</td>\n",
       "      <td>ph·ª©c t·∫°p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16526</th>\n",
       "      <td>nag261</td>\n",
       "      <td>1</td>\n",
       "      <td>·∫ø ·∫©m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16527</th>\n",
       "      <td>nag262</td>\n",
       "      <td>1</td>\n",
       "      <td>·∫ø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16528</th>\n",
       "      <td>nag263</td>\n",
       "      <td>1</td>\n",
       "      <td>s∆∞·ªõt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16529 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id label                                             review\n",
       "0      train_000000     0  \"Dung dc sp tot cam onshop ƒê√≥ng g√≥i s·∫£n ph·∫©m r...\n",
       "1      train_000001     0  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi . Son m·ªãn nh∆∞n...\n",
       "2      train_000002     0  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi nh∆∞ng k c√≥ h·ªôp...\n",
       "3      train_000003     1  \":(( M√¨nh h∆°i th·∫•t v·ªçng 1 ch√∫t v√¨ m√¨nh ƒë√£ k·ª≥ v...\n",
       "4      train_000004     1  \"L·∫ßn tr∆∞·ªõc m√¨nh mua √°o gi√≥ m√†u h·ªìng r·∫•t ok m√† ...\n",
       "...             ...   ...                                                ...\n",
       "16524        nag259     1                                                l·ªôn\n",
       "16525        nag260     1                                           ph·ª©c t·∫°p\n",
       "16526        nag261     1                                               ·∫ø ·∫©m\n",
       "16527        nag262     1                                                  ·∫ø\n",
       "16528        nag263     1                                               s∆∞·ªõt\n",
       "\n",
       "[16529 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_000000</td>\n",
       "      <td>\"Ch∆∞a d√πng th·ª≠ n√™n ch∆∞a bi·∫øt\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_000001</td>\n",
       "      <td>\" Kh√¥ng ƒë√°ng ti·ªÅnV√¨ ngay ƒë·ª£t sale n√™n m·ªõi mua ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_000002</td>\n",
       "      <td>\"C√°m ∆°n shop. ƒê√≥ng g√≥i s·∫£n ph·∫©m r·∫•t ƒë·∫πp v√† ch·∫Ø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_000003</td>\n",
       "      <td>\"V·∫£i ƒë·∫πp.phom oki lu√¥n.qu√° ∆∞ng\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_000004</td>\n",
       "      <td>\"Chu·∫©n h√†ng ƒë√≥ng g√≥i ƒë·∫πp\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>test_010976</td>\n",
       "      <td>\" Th·ªùi gian giao h√†ng r·∫•t nhanh.ngon.m√† cay qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>test_010977</td>\n",
       "      <td>\"S·∫£n ph·∫©m h∆°i c≈©\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>test_010978</td>\n",
       "      <td>\"S·∫£n ph·∫©m ch·∫Øc ch·∫Øn nh∆∞ng k b√≥ng b·∫±ng trong h√¨nh\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>test_010979</td>\n",
       "      <td>\" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi c√≥ m√πi th∆°m r·∫•...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>test_010980</td>\n",
       "      <td>\"nh∆∞ qu·∫£ng c√°o. sim r·∫•t t·ªët\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10981 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                             review\n",
       "0      test_000000                      \"Ch∆∞a d√πng th·ª≠ n√™n ch∆∞a bi·∫øt\"\n",
       "1      test_000001  \" Kh√¥ng ƒë√°ng ti·ªÅnV√¨ ngay ƒë·ª£t sale n√™n m·ªõi mua ...\n",
       "2      test_000002  \"C√°m ∆°n shop. ƒê√≥ng g√≥i s·∫£n ph·∫©m r·∫•t ƒë·∫πp v√† ch·∫Ø...\n",
       "3      test_000003                    \"V·∫£i ƒë·∫πp.phom oki lu√¥n.qu√° ∆∞ng\"\n",
       "4      test_000004                          \"Chu·∫©n h√†ng ƒë√≥ng g√≥i ƒë·∫πp\"\n",
       "...            ...                                                ...\n",
       "10976  test_010976  \" Th·ªùi gian giao h√†ng r·∫•t nhanh.ngon.m√† cay qu...\n",
       "10977  test_010977                                  \"S·∫£n ph·∫©m h∆°i c≈©\"\n",
       "10978  test_010978  \"S·∫£n ph·∫©m ch·∫Øc ch·∫Øn nh∆∞ng k b√≥ng b·∫±ng trong h√¨nh\"\n",
       "10979  test_010979  \" Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi c√≥ m√πi th∆°m r·∫•...\n",
       "10980  test_010980                       \"nh∆∞ qu·∫£ng c√°o. sim r·∫•t t·ªët\"\n",
       "\n",
       "[10981 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSource()\n",
    "X_train, y_train = ds.transform_to_dataset(train_data.review, train_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33058"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33058"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3,\n",
    "                                                        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 150\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 150, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 96,337\n",
      "Trainable params: 96,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 18512 samples, validate on 4628 samples\n",
      "Epoch 1/10\n",
      "18512/18512 [==============================] - 32s 2ms/step - loss: 0.3380 - accuracy: 0.8613 - val_loss: 0.2710 - val_accuracy: 0.8948\n",
      "Epoch 2/10\n",
      "18512/18512 [==============================] - 30s 2ms/step - loss: 0.2533 - accuracy: 0.9044 - val_loss: 0.2594 - val_accuracy: 0.8987\n",
      "Epoch 3/10\n",
      "18512/18512 [==============================] - 35s 2ms/step - loss: 0.2408 - accuracy: 0.9100 - val_loss: 0.2740 - val_accuracy: 0.8933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2a9b60b05c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix,y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9918/9918 [==============================] - 8s 783us/step\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(test_sequences_matrix,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "  Loss: 0.286\n",
      "  Accuracy: 0.888\n"
     ]
    }
   ],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(sequences_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23140"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23140, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [i for i in range((y_pred).shape[0]) if y_pred[i]>=0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 14,\n",
       " 16,\n",
       " 18,\n",
       " 20,\n",
       " 22,\n",
       " 25,\n",
       " 29,\n",
       " 34,\n",
       " 39,\n",
       " 42,\n",
       " 43,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 52,\n",
       " 54,\n",
       " 57,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 63,\n",
       " 65,\n",
       " 67,\n",
       " 69,\n",
       " 73,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 92,\n",
       " 96,\n",
       " 101,\n",
       " 105,\n",
       " 112,\n",
       " 118,\n",
       " 119,\n",
       " 121,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 131,\n",
       " 133,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 144,\n",
       " 145,\n",
       " 148,\n",
       " 157,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 169,\n",
       " 172,\n",
       " 178,\n",
       " 183,\n",
       " 184,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 195,\n",
       " 197,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 203,\n",
       " 207,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 224,\n",
       " 225,\n",
       " 228,\n",
       " 230,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 249,\n",
       " 250,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 262,\n",
       " 263,\n",
       " 267,\n",
       " 269,\n",
       " 272,\n",
       " 273,\n",
       " 275,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 284,\n",
       " 289,\n",
       " 293,\n",
       " 295,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 309,\n",
       " 311,\n",
       " 315,\n",
       " 317,\n",
       " 323,\n",
       " 325,\n",
       " 326,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 343,\n",
       " 345,\n",
       " 352,\n",
       " 355,\n",
       " 359,\n",
       " 360,\n",
       " 363,\n",
       " 364,\n",
       " 369,\n",
       " 371,\n",
       " 373,\n",
       " 374,\n",
       " 378,\n",
       " 379,\n",
       " 381,\n",
       " 383,\n",
       " 384,\n",
       " 390,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 396,\n",
       " 399,\n",
       " 400,\n",
       " 402,\n",
       " 404,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 415,\n",
       " 418,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 428,\n",
       " 429,\n",
       " 431,\n",
       " 436,\n",
       " 439,\n",
       " 440,\n",
       " 442,\n",
       " 444,\n",
       " 445,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 452,\n",
       " 454,\n",
       " 456,\n",
       " 457,\n",
       " 459,\n",
       " 460,\n",
       " 463,\n",
       " 465,\n",
       " 471,\n",
       " 472,\n",
       " 479,\n",
       " 482,\n",
       " 484,\n",
       " 487,\n",
       " 488,\n",
       " 491,\n",
       " 493,\n",
       " 498,\n",
       " 504,\n",
       " 505,\n",
       " 512,\n",
       " 516,\n",
       " 521,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 531,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 551,\n",
       " 554,\n",
       " 555,\n",
       " 557,\n",
       " 561,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 567,\n",
       " 571,\n",
       " 573,\n",
       " 575,\n",
       " 576,\n",
       " 579,\n",
       " 580,\n",
       " 583,\n",
       " 590,\n",
       " 591,\n",
       " 594,\n",
       " 595,\n",
       " 597,\n",
       " 600,\n",
       " 606,\n",
       " 609,\n",
       " 611,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 620,\n",
       " 623,\n",
       " 631,\n",
       " 634,\n",
       " 635,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 643,\n",
       " 646,\n",
       " 650,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 662,\n",
       " 664,\n",
       " 667,\n",
       " 668,\n",
       " 673,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 679,\n",
       " 680,\n",
       " 685,\n",
       " 688,\n",
       " 691,\n",
       " 693,\n",
       " 704,\n",
       " 708,\n",
       " 712,\n",
       " 713,\n",
       " 715,\n",
       " 716,\n",
       " 720,\n",
       " 721,\n",
       " 724,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 734,\n",
       " 738,\n",
       " 740,\n",
       " 741,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 748,\n",
       " 753,\n",
       " 755,\n",
       " 756,\n",
       " 757,\n",
       " 758,\n",
       " 759,\n",
       " 764,\n",
       " 765,\n",
       " 769,\n",
       " 770,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 778,\n",
       " 783,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 805,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 815,\n",
       " 816,\n",
       " 820,\n",
       " 823,\n",
       " 827,\n",
       " 828,\n",
       " 830,\n",
       " 832,\n",
       " 833,\n",
       " 837,\n",
       " 839,\n",
       " 840,\n",
       " 848,\n",
       " 849,\n",
       " 851,\n",
       " 858,\n",
       " 861,\n",
       " 864,\n",
       " 870,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 883,\n",
       " 885,\n",
       " 888,\n",
       " 890,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 896,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 904,\n",
       " 905,\n",
       " 909,\n",
       " 914,\n",
       " 916,\n",
       " 917,\n",
       " 921,\n",
       " 923,\n",
       " 924,\n",
       " 925,\n",
       " 926,\n",
       " 927,\n",
       " 931,\n",
       " 932,\n",
       " 935,\n",
       " 936,\n",
       " 938,\n",
       " 940,\n",
       " 946,\n",
       " 947,\n",
       " 949,\n",
       " 952,\n",
       " 954,\n",
       " 956,\n",
       " 958,\n",
       " 959,\n",
       " 960,\n",
       " 963,\n",
       " 964,\n",
       " 973,\n",
       " 976,\n",
       " 978,\n",
       " 980,\n",
       " 981,\n",
       " 983,\n",
       " 987,\n",
       " 988,\n",
       " 991,\n",
       " 994,\n",
       " 995,\n",
       " 998,\n",
       " 999,\n",
       " 1001,\n",
       " 1003,\n",
       " 1004,\n",
       " 1005,\n",
       " 1008,\n",
       " 1009,\n",
       " 1010,\n",
       " 1014,\n",
       " 1015,\n",
       " 1017,\n",
       " 1019,\n",
       " 1020,\n",
       " 1027,\n",
       " 1030,\n",
       " 1032,\n",
       " 1033,\n",
       " 1034,\n",
       " 1041,\n",
       " 1042,\n",
       " 1047,\n",
       " 1048,\n",
       " 1050,\n",
       " 1051,\n",
       " 1052,\n",
       " 1054,\n",
       " 1056,\n",
       " 1060,\n",
       " 1061,\n",
       " 1063,\n",
       " 1066,\n",
       " 1067,\n",
       " 1068,\n",
       " 1069,\n",
       " 1071,\n",
       " 1076,\n",
       " 1078,\n",
       " 1079,\n",
       " 1089,\n",
       " 1090,\n",
       " 1094,\n",
       " 1095,\n",
       " 1099,\n",
       " 1102,\n",
       " 1103,\n",
       " 1105,\n",
       " 1112,\n",
       " 1114,\n",
       " 1115,\n",
       " 1117,\n",
       " 1118,\n",
       " 1120,\n",
       " 1122,\n",
       " 1126,\n",
       " 1128,\n",
       " 1133,\n",
       " 1137,\n",
       " 1147,\n",
       " 1151,\n",
       " 1154,\n",
       " 1156,\n",
       " 1157,\n",
       " 1158,\n",
       " 1159,\n",
       " 1160,\n",
       " 1163,\n",
       " 1167,\n",
       " 1171,\n",
       " 1174,\n",
       " 1179,\n",
       " 1183,\n",
       " 1184,\n",
       " 1187,\n",
       " 1189,\n",
       " 1190,\n",
       " 1191,\n",
       " 1196,\n",
       " 1202,\n",
       " 1206,\n",
       " 1207,\n",
       " 1209,\n",
       " 1211,\n",
       " 1212,\n",
       " 1213,\n",
       " 1214,\n",
       " 1219,\n",
       " 1221,\n",
       " 1224,\n",
       " 1225,\n",
       " 1230,\n",
       " 1231,\n",
       " 1233,\n",
       " 1234,\n",
       " 1237,\n",
       " 1238,\n",
       " 1239,\n",
       " 1240,\n",
       " 1246,\n",
       " 1248,\n",
       " 1254,\n",
       " 1255,\n",
       " 1256,\n",
       " 1259,\n",
       " 1262,\n",
       " 1264,\n",
       " 1268,\n",
       " 1273,\n",
       " 1277,\n",
       " 1279,\n",
       " 1280,\n",
       " 1283,\n",
       " 1284,\n",
       " 1285,\n",
       " 1287,\n",
       " 1288,\n",
       " 1290,\n",
       " 1293,\n",
       " 1297,\n",
       " 1298,\n",
       " 1299,\n",
       " 1301,\n",
       " 1305,\n",
       " 1306,\n",
       " 1307,\n",
       " 1308,\n",
       " 1314,\n",
       " 1315,\n",
       " 1316,\n",
       " 1317,\n",
       " 1318,\n",
       " 1327,\n",
       " 1328,\n",
       " 1332,\n",
       " 1336,\n",
       " 1337,\n",
       " 1339,\n",
       " 1341,\n",
       " 1348,\n",
       " 1351,\n",
       " 1352,\n",
       " 1354,\n",
       " 1360,\n",
       " 1361,\n",
       " 1362,\n",
       " 1365,\n",
       " 1367,\n",
       " 1369,\n",
       " 1371,\n",
       " 1372,\n",
       " 1380,\n",
       " 1381,\n",
       " 1382,\n",
       " 1386,\n",
       " 1387,\n",
       " 1390,\n",
       " 1392,\n",
       " 1394,\n",
       " 1395,\n",
       " 1399,\n",
       " 1401,\n",
       " 1404,\n",
       " 1408,\n",
       " 1409,\n",
       " 1410,\n",
       " 1411,\n",
       " 1413,\n",
       " 1415,\n",
       " 1419,\n",
       " 1420,\n",
       " 1424,\n",
       " 1426,\n",
       " 1427,\n",
       " 1432,\n",
       " 1436,\n",
       " 1437,\n",
       " 1438,\n",
       " 1440,\n",
       " 1441,\n",
       " 1443,\n",
       " 1444,\n",
       " 1452,\n",
       " 1454,\n",
       " 1459,\n",
       " 1460,\n",
       " 1461,\n",
       " 1462,\n",
       " 1464,\n",
       " 1465,\n",
       " 1467,\n",
       " 1470,\n",
       " 1471,\n",
       " 1472,\n",
       " 1473,\n",
       " 1475,\n",
       " 1478,\n",
       " 1479,\n",
       " 1481,\n",
       " 1482,\n",
       " 1485,\n",
       " 1486,\n",
       " 1488,\n",
       " 1490,\n",
       " 1492,\n",
       " 1495,\n",
       " 1496,\n",
       " 1499,\n",
       " 1501,\n",
       " 1505,\n",
       " 1511,\n",
       " 1513,\n",
       " 1516,\n",
       " 1518,\n",
       " 1519,\n",
       " 1520,\n",
       " 1524,\n",
       " 1525,\n",
       " 1530,\n",
       " 1531,\n",
       " 1535,\n",
       " 1536,\n",
       " 1538,\n",
       " 1539,\n",
       " 1540,\n",
       " 1541,\n",
       " 1543,\n",
       " 1546,\n",
       " 1548,\n",
       " 1553,\n",
       " 1554,\n",
       " 1555,\n",
       " 1557,\n",
       " 1559,\n",
       " 1560,\n",
       " 1565,\n",
       " 1567,\n",
       " 1572,\n",
       " 1576,\n",
       " 1578,\n",
       " 1580,\n",
       " 1586,\n",
       " 1587,\n",
       " 1590,\n",
       " 1591,\n",
       " 1593,\n",
       " 1596,\n",
       " 1598,\n",
       " 1602,\n",
       " 1604,\n",
       " 1607,\n",
       " 1609,\n",
       " 1612,\n",
       " 1613,\n",
       " 1616,\n",
       " 1618,\n",
       " 1621,\n",
       " 1622,\n",
       " 1626,\n",
       " 1629,\n",
       " 1631,\n",
       " 1633,\n",
       " 1634,\n",
       " 1635,\n",
       " 1636,\n",
       " 1637,\n",
       " 1638,\n",
       " 1639,\n",
       " 1641,\n",
       " 1642,\n",
       " 1644,\n",
       " 1647,\n",
       " 1650,\n",
       " 1652,\n",
       " 1656,\n",
       " 1658,\n",
       " 1660,\n",
       " 1662,\n",
       " 1663,\n",
       " 1665,\n",
       " 1666,\n",
       " 1670,\n",
       " 1672,\n",
       " 1675,\n",
       " 1676,\n",
       " 1677,\n",
       " 1678,\n",
       " 1679,\n",
       " 1685,\n",
       " 1689,\n",
       " 1690,\n",
       " 1693,\n",
       " 1696,\n",
       " 1697,\n",
       " 1698,\n",
       " 1701,\n",
       " 1704,\n",
       " 1705,\n",
       " 1709,\n",
       " 1712,\n",
       " 1713,\n",
       " 1719,\n",
       " 1724,\n",
       " 1728,\n",
       " 1731,\n",
       " 1732,\n",
       " 1738,\n",
       " 1739,\n",
       " 1740,\n",
       " 1742,\n",
       " 1743,\n",
       " 1746,\n",
       " 1751,\n",
       " 1752,\n",
       " 1756,\n",
       " 1757,\n",
       " 1760,\n",
       " 1761,\n",
       " 1764,\n",
       " 1766,\n",
       " 1770,\n",
       " 1771,\n",
       " 1773,\n",
       " 1774,\n",
       " 1775,\n",
       " 1777,\n",
       " 1778,\n",
       " 1779,\n",
       " 1784,\n",
       " 1786,\n",
       " 1788,\n",
       " 1789,\n",
       " 1790,\n",
       " 1792,\n",
       " 1795,\n",
       " 1805,\n",
       " 1808,\n",
       " 1811,\n",
       " 1812,\n",
       " 1814,\n",
       " 1826,\n",
       " 1830,\n",
       " 1833,\n",
       " 1834,\n",
       " 1838,\n",
       " 1839,\n",
       " 1840,\n",
       " 1841,\n",
       " 1843,\n",
       " 1844,\n",
       " 1846,\n",
       " 1851,\n",
       " 1852,\n",
       " 1853,\n",
       " 1858,\n",
       " 1859,\n",
       " 1863,\n",
       " 1864,\n",
       " 1866,\n",
       " 1868,\n",
       " 1876,\n",
       " 1877,\n",
       " 1879,\n",
       " 1880,\n",
       " 1881,\n",
       " 1886,\n",
       " 1887,\n",
       " 1888,\n",
       " 1889,\n",
       " 1890,\n",
       " 1891,\n",
       " 1892,\n",
       " 1893,\n",
       " 1895,\n",
       " 1897,\n",
       " 1898,\n",
       " 1905,\n",
       " 1907,\n",
       " 1909,\n",
       " 1910,\n",
       " 1912,\n",
       " 1913,\n",
       " 1917,\n",
       " 1918,\n",
       " 1923,\n",
       " 1927,\n",
       " 1928,\n",
       " 1930,\n",
       " 1934,\n",
       " 1942,\n",
       " 1944,\n",
       " 1945,\n",
       " 1946,\n",
       " 1947,\n",
       " 1949,\n",
       " 1950,\n",
       " 1954,\n",
       " 1955,\n",
       " 1957,\n",
       " 1959,\n",
       " 1960,\n",
       " 1961,\n",
       " 1962,\n",
       " 1964,\n",
       " 1966,\n",
       " 1970,\n",
       " 1971,\n",
       " 1974,\n",
       " 1975,\n",
       " 1976,\n",
       " 1980,\n",
       " 1981,\n",
       " 1987,\n",
       " 1988,\n",
       " 1989,\n",
       " 1990,\n",
       " 1991,\n",
       " 1993,\n",
       " 1996,\n",
       " 1997,\n",
       " 1998,\n",
       " 2000,\n",
       " 2002,\n",
       " 2004,\n",
       " 2006,\n",
       " 2007,\n",
       " 2008,\n",
       " 2012,\n",
       " 2017,\n",
       " 2023,\n",
       " 2024,\n",
       " 2030,\n",
       " 2032,\n",
       " 2035,\n",
       " 2037,\n",
       " 2038,\n",
       " 2040,\n",
       " 2041,\n",
       " 2042,\n",
       " 2046,\n",
       " 2047,\n",
       " 2048,\n",
       " 2050,\n",
       " 2053,\n",
       " 2055,\n",
       " 2056,\n",
       " 2058,\n",
       " 2060,\n",
       " 2061,\n",
       " 2064,\n",
       " 2065,\n",
       " 2066,\n",
       " 2067,\n",
       " 2068,\n",
       " 2069,\n",
       " 2071,\n",
       " 2074,\n",
       " 2076,\n",
       " 2080,\n",
       " 2081,\n",
       " 2085,\n",
       " 2087,\n",
       " 2089,\n",
       " 2092,\n",
       " 2093,\n",
       " 2094,\n",
       " 2097,\n",
       " 2098,\n",
       " 2101,\n",
       " 2102,\n",
       " 2115,\n",
       " 2117,\n",
       " 2118,\n",
       " 2120,\n",
       " 2121,\n",
       " 2124,\n",
       " 2126,\n",
       " 2127,\n",
       " 2128,\n",
       " 2135,\n",
       " 2136,\n",
       " 2137,\n",
       " 2138,\n",
       " 2142,\n",
       " 2143,\n",
       " 2144,\n",
       " 2146,\n",
       " 2147,\n",
       " 2151,\n",
       " 2152,\n",
       " 2153,\n",
       " 2154,\n",
       " 2156,\n",
       " 2157,\n",
       " 2159,\n",
       " 2160,\n",
       " 2165,\n",
       " 2170,\n",
       " 2171,\n",
       " 2174,\n",
       " 2175,\n",
       " 2178,\n",
       " 2179,\n",
       " 2180,\n",
       " 2183,\n",
       " 2184,\n",
       " 2188,\n",
       " 2189,\n",
       " 2190,\n",
       " 2192,\n",
       " 2194,\n",
       " 2195,\n",
       " 2198,\n",
       " 2199,\n",
       " 2201,\n",
       " 2204,\n",
       " 2206,\n",
       " 2208,\n",
       " 2212,\n",
       " 2213,\n",
       " 2218,\n",
       " 2221,\n",
       " 2224,\n",
       " 2228,\n",
       " 2230,\n",
       " 2231,\n",
       " 2242,\n",
       " 2244,\n",
       " 2246,\n",
       " 2249,\n",
       " 2255,\n",
       " 2256,\n",
       " 2258,\n",
       " 2261,\n",
       " 2264,\n",
       " 2268,\n",
       " 2270,\n",
       " 2271,\n",
       " 2278,\n",
       " 2284,\n",
       " 2285,\n",
       " 2286,\n",
       " 2288,\n",
       " 2292,\n",
       " 2295,\n",
       " 2296,\n",
       " 2298,\n",
       " 2300,\n",
       " 2305,\n",
       " 2308,\n",
       " 2312,\n",
       " 2314,\n",
       " 2319,\n",
       " 2325,\n",
       " 2332,\n",
       " 2334,\n",
       " 2339,\n",
       " 2349,\n",
       " 2352,\n",
       " 2356,\n",
       " 2357,\n",
       " 2359,\n",
       " 2372,\n",
       " 2376,\n",
       " 2377,\n",
       " 2379,\n",
       " 2386,\n",
       " 2390,\n",
       " 2394,\n",
       " 2397,\n",
       " 2398,\n",
       " 2399,\n",
       " 2400,\n",
       " 2402,\n",
       " 2403,\n",
       " 2405,\n",
       " 2410,\n",
       " 2411,\n",
       " 2414,\n",
       " 2415,\n",
       " 2416,\n",
       " 2417,\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94863534], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.4863534e-01],\n",
       "       [9.8693687e-01],\n",
       "       [3.7550884e-01],\n",
       "       [7.0323932e-01],\n",
       "       [3.4781185e-01],\n",
       "       [2.9617548e-04],\n",
       "       [2.2804737e-04],\n",
       "       [9.3835771e-01],\n",
       "       [2.8188825e-03],\n",
       "       [8.3068597e-01]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
